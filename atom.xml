<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Marcus Young]]></title>
  <link href="http://marcyoung.us/atom.xml" rel="self"/>
  <link href="http://marcyoung.us/"/>
  <updated>2016-08-09T16:01:24-05:00</updated>
  <id>http://marcyoung.us/</id>
  <author>
    <name><![CDATA[Marcus Young]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[AWS ECS Hot/Warm ELK + Curator Part 4 - Curator]]></title>
    <link href="http://marcyoung.us/post/dockerized-elk-part-4"/>
    <updated>2016-08-08T00:00:00-05:00</updated>
    <id>http://marcyoung.us/post/dockerized-elk-part4</id>
    <content type="html"><![CDATA[<p>The previous part focused on getting Kibana up. This one focuses on getting Curator <!-- more --></p>

<h1>Disclaimer</h1>

<p>I&rsquo;m redacting any information that might seem sensitive such as account numbers. Use your discretion and make sure you use values that make sense for things blacked out in images or in <code>{}</code> notation.</p>

<h1>Part 2 - Curator</h1>

<p>This is the coolest part of the whole stack.</p>

<p>We&rsquo;re basically going to build/deploy a docker image for Curator, then upload a cloudformation template that creates a Lambda function to run it.</p>

<p>The lambda function will have a trigger of your choice (probably a scheduled event for once a day if I had to guess) and will run two tasks.</p>

<p>Task 1 is a rotate warm task that will tell Elasticsearch to move any indexes to warm that (in this case) are 0 days old (for demo purposes).
Task 2 is a delete task that tells Elasticsearch to delete any indexes older than 14 days.</p>

<p>You can expand this to stagger them, take snapshots, etc. This allows you to have schedules that define how the data moves from box to box or to backups!</p>

<p>First thing we need to do is build the container and push it to ECR.</p>

<p>In the ECR portion of the AWS console, create a new repository called <code>test/curator</code>.</p>

<p>Then in your console for <a href="https://github.com/myoung34/elk-docker-aws/blob/master/curator/Dockerfile">the curator dockerfile</a> run:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>docker build -t curator:local .
</span><span class='line'>docker tag curator:local \
</span><span class='line'>   {acctnum}.dkr.ecr.us-east-1.amazonaws.com/test/curator:latest
</span><span class='line'>$(aws ecr get-login)
</span><span class='line'>docker push {acctnum}.dkr.ecr.us-east-1.amazonaws.com/test/curator:latest</span></code></pre></td></tr></table></div></figure>


<p>Once this is pushed you can verify it by looking for a tag <code>latest</code> in your <code>test/curator</code> ECR repository.</p>

<p>Next upload <a href="https://github.com/myoung34/elk-docker-aws/blob/master/curator/cloudformation.json">this cloudformation template</a> to Cloudformation (modifying the parameters as you need).</p>

<p><img src="../../images/elk/curator_cft_params.png" alt="" /></p>

<p>Once it is complete, go to the Lambda portion of AWS and click your function that was created. You can test it by clicking &ldquo;Test&rdquo; and just hitting &ldquo;submit&rdquo;.</p>

<p>You will see some output such as:</p>

<p><img src="../../images/elk/curator_lambda.png" alt="" /></p>

<p>If you go to the ECS console quickly you will see two tasks have been created and are being run for the first time (will be in pending for a minute while the image is being pulled to the instance running it).</p>

<p><img src="../../images/elk/curator_delete_task.png" alt="" /></p>

<p><img src="../../images/elk/curator_rotate_warm_task.png" alt="" /></p>

<p>And now if you look at your kopf plugin you will see the data move from the &ldquo;hot&rdquo; node:</p>

<p><img src="../../images/elk/curator_before.png" alt="" /></p>

<p>To eventually the &ldquo;warm&rdquo; node:</p>

<p><img src="../../images/elk/curator_after.png" alt="" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS ECS Hot/Warm ELK + Curator Part 3 - Kibana]]></title>
    <link href="http://marcyoung.us/post/dockerized-elk-part-3"/>
    <updated>2016-08-08T00:00:00-05:00</updated>
    <id>http://marcyoung.us/post/dockerized-elk-part3</id>
    <content type="html"><![CDATA[<p>The previous part focused on getting logstash up. This one focuses on getting Kibana <!-- more --></p>

<h1>Disclaimer</h1>

<p>I&rsquo;m redacting any information that might seem sensitive such as account numbers. Use your discretion and make sure you use values that make sense for things blacked out in images or in <code>{}</code> notation.</p>

<h1>Part 2 - Kibana</h1>

<p>First thing we need to do is build the container and push it to ECR.</p>

<p>In the ECR portion of the AWS console, create a new repository called <code>test/kibana</code>.</p>

<p>Then in your console for <a href="https://github.com/myoung34/elk-docker-aws/blob/master/kibana/Dockerfile">the kibana dockerfile</a> run:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>docker build -t kibana:local .
</span><span class='line'>docker tag kibana:local \
</span><span class='line'>   {acctnum}.dkr.ecr.us-east-1.amazonaws.com/test/kibana:latest
</span><span class='line'>$(aws ecr get-login)
</span><span class='line'>docker push {acctnum}.dkr.ecr.us-east-1.amazonaws.com/test/kibana:latest</span></code></pre></td></tr></table></div></figure>


<p>Once this is pushed you can verify it by looking for a tag <code>latest</code> in your <code>test/kibana</code> ECR repository.</p>

<p>Next upload <a href="https://github.com/myoung34/elk-docker-aws/blob/master/kibana/cloudformation.json">this cloudformation template</a> to Cloudformation (modifying the parameters as you need).</p>

<p>It will look almost exactly like the logstash upload in terms of parameters.</p>

<p>You now have a kibana instance! My next step would be to configure a Route53 domain name to point to the kibana load balancer so you can have real SSL without any chain issues.</p>

<h1>Takeaways</h1>

<p>Similar to what we did with elasticsearch and logstash, kibana is listening on port <code>5601</code> via HTTPS. It uses self-signed SSL certificates. The dockerfile is actually identical to the verified one on the Dockerhub, except I expanded the <code>docker-entrypoint.sh</code> to take more parameters since the base one doesn&rsquo;t allow much configurability: <a href="https://github.com/docker-library/kibana/pull/45">https://github.com/docker-library/kibana/pull/45</a></p>

<p>If you browse to your ELB or route53 entry on port 443, you&rsquo;ll be greeted by kibana.</p>

<p><img src="../../images/elk/kibana_first.png" alt="" /></p>

<p>If you configure your index to <code>test-*</code> your dashboard will show the logs Logstash ingested!</p>

<p><img src="../../images/elk/kibana_dash.png" alt="" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS ECS Hot/Warm ELK + Curator Part 2 - Logstash]]></title>
    <link href="http://marcyoung.us/post/dockerized-elk-part-2"/>
    <updated>2016-08-08T00:00:00-05:00</updated>
    <id>http://marcyoung.us/post/dockerized-elk-part2</id>
    <content type="html"><![CDATA[<p>The previous part focused on getting the ECS cluster, ECR repos, and Elasticsearch up. This one focuses on getting Logstash <!-- more --></p>

<h1>Disclaimer</h1>

<p>I&rsquo;m redacting any information that might seem sensitive such as account numbers. Use your discretion and make sure you use values that make sense for things blacked out in images or in <code>{}</code> notation.</p>

<h1>Part 2a - Logstash</h1>

<p>First thing we need to do is build the container and push it to ECR.</p>

<p>In the ECR portion of the AWS console, create a new repository called <code>test/logstash</code>.</p>

<p>Then in your console for <a href="https://github.com/myoung34/elk-docker-aws/blob/master/logstash/Dockerfile">the logstash dockerfile</a> run:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>docker build -t logstash:local .
</span><span class='line'>docker tag logstash:local \
</span><span class='line'>   {acctnum}.dkr.ecr.us-east-1.amazonaws.com/test/logstash:latest
</span><span class='line'>$(aws ecr get-login)
</span><span class='line'>docker push {acctnum}.dkr.ecr.us-east-1.amazonaws.com/test/logstash:latest</span></code></pre></td></tr></table></div></figure>


<p>Once this is pushed you can verify it by looking for a tag <code>latest</code> in your <code>test/logstash</code> ECR repository.</p>

<p>Next upload <a href="https://github.com/myoung34/elk-docker-aws/blob/master/logstash/cloudformation.json">this cloudformation template</a> to Cloudformation (modifying the parameters as you need).</p>

<p><img src="../../images/elk/logstash_cft.png" alt="" /></p>

<p>You now have a listening logstash instance! My next step would be to configure a Route53 domain name to point to the logstash load balancer so you can have real SSL without any chain issues.</p>

<h1>Takeaways</h1>

<p>Similar to what we did with elasticsearch, logstash is listening on port <code>5000</code> for beats input. It uses self-signed SSL certificates. Most beats forwarders won&rsquo;t play nice with that out of the box, but if you configure Route53 to point to the ELB and use ACM, it will be valid SSL. The load balancer will use TCP to send to the logstash instances and not care that it is self-signed.</p>

<p>The <a href="https://github.com/myoung34/elk-docker-aws/blob/master/logstash/logstash.conf">logstash configuration file</a> uses dynamic indexes, so whatever you set <code>document_type</code> on your beats configuration to will become the index.</p>

<h1>Part 2b - Send to logstash</h1>

<p>Install the latest stable logstash and use this filebeat configuration to get ready to ship:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>filebeat:
</span><span class='line'>  prospectors:
</span><span class='line'>    -
</span><span class='line'>      paths:
</span><span class='line'>        - "/var/log/test/*"
</span><span class='line'>      encoding: plain
</span><span class='line'>      input_type: log
</span><span class='line'>      fields_under_root: true
</span><span class='line'>      document_type: test
</span><span class='line'>output:
</span><span class='line'>  logstash:
</span><span class='line'>    hosts: ["log-test.dev.mydom.com:5000"]</span></code></pre></td></tr></table></div></figure>


<p>Next make sure that directory exists via <code>sudo mkdir /var/log/test</code> and start the service (depends on your OS): <code>sudo service filebeat start</code>.</p>

<p>Lastly, lets send something to logstash: <code>echo asdf | sudo tee -a /var/log/test/$(uuidgen)</code>. That will generate a random file and put <code>asdf</code> into it. It should show up in your kopf plugin to view:</p>

<p><img src="../../images/elk/logstash_kopf.png" alt="" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS ECS Hot/Warm ELK + Curator Part 1 - Elasticsearch]]></title>
    <link href="http://marcyoung.us/post/dockerized-elk-part-1"/>
    <updated>2016-08-08T00:00:00-05:00</updated>
    <id>http://marcyoung.us/post/dockerized-elk-part1</id>
    <content type="html"><![CDATA[<p>This will be a write-up on how to get a self-healing and self-curating SSL-enabled Hot/Warm ELK stack using ECS and lambda <!-- more --></p>

<h1>Disclaimer</h1>

<p>I&rsquo;m redacting any information that might seem sensitive such as account numbers. Use your discretion and make sure you use values that make sense for things blacked out in images or in <code>{}</code> notation.</p>

<h1>Part 1a - ECS Base Instances</h1>

<p>This is actually one of the easier pieces. We need a base ECS cluster to run our tasks on. <a href="https://github.com/myoung34/elk-docker-aws/blob/master/ecs_base/cloudformation.json">This cloudformation template</a> assumes your VPC is connectible, etc. If your VPC is compatible, just upload that file in cloudformation and when it&rsquo;s done, you&rsquo;ll have a cluster ready!</p>

<p>The params tab:</p>

<p><img src="../../images/elk/elk_base_cft.png" alt="" /></p>

<p>After completion:</p>

<p><img src="../../images/elk/elk_base_cft_output.png" alt="" /></p>

<p>If you were to go to your ECS tab in your AWS console, you will see a new cluster with the name <code>elk-stack-ECSCluster-1A5AXF087VXOD</code> and eventually you would have 4 EC2 instances available for running tasks.</p>

<h1>Part 1b - Elasticsearch</h1>

<p>First thing we need to do is build the container and push it to ECR.</p>

<p>In the ECR portion of the AWS console, create a new repository called <code>test/elasticsearch</code>.</p>

<p>Then in your console for <a href="https://github.com/myoung34/elk-docker-aws/tree/master/elasticsearch">the elasticsearch dockerfile</a> run:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>docker build -t elasticsearch:local .
</span><span class='line'>docker tag elasticsearch:local \
</span><span class='line'>   {acctnum}.dkr.ecr.us-east-1.amazonaws.com/test/elasticsearch:latest
</span><span class='line'>$(aws ecr get-login)
</span><span class='line'>docker push {acctnum}.dkr.ecr.us-east-1.amazonaws.com/test/elasticsearch:latest</span></code></pre></td></tr></table></div></figure>


<p>Once this is pushed you can verify it by looking for a tag <code>latest</code> in your <code>test/elasticsearch</code> ECR repository.</p>

<p>Next upload <a href="https://github.com/myoung34/elk-docker-aws/blob/master/elasticsearch/cloudformation.json">this cloudformation template</a> to Cloudformation (modifying the parameters as you need).</p>

<p>The parameters I used:</p>

<p><img src="../../images/elk/elasticsearch_cft_params.png" alt="" /></p>

<p>And the output tab:</p>

<p><img src="../../images/elk/elasticsearch_cft_output.png" alt="" /></p>

<p>If you paid enough attention to the code in the <a href="https://github.com/myoung34/elk-docker-aws/blob/master/elasticsearch/docker-entrypoint.sh">docker-entrypoint.sh</a> file you might notice this line: <code>export NODE_TYPE=$([[ `echo $((1 + RANDOM % 2))` -eq "1" ]] &amp;&amp; echo warm || echo hot)</code>.</p>

<p>That, along with the <a href="https://github.com/myoung34/elk-docker-aws/blob/master/elasticsearch/elasticsearch.yml">elasticsearch configuration yaml</a>, namely the line: <code>node.box_type: ${NODE_TYPE}</code> gives you a random 50/50 chance of getting a &ldquo;hot&rdquo; or &ldquo;warm&rdquo; node. <a href="https://www.elastic.co/blog/hot-warm-architecture">The hot/warm architecture is outlined here</a> but basically you&rsquo;re going to have nodes that have attributes <code>box_type: hot</code> or <code>box_type: warm</code>. We&rsquo;ll go over how the data matters later, but for now you can verify that like in these screen shots by browsing to your elastic load balancer such as: <code>internal-elasticse-ESElasti-WYA9ZLRBVV8X-214980960.us-east-1.elb.amazonaws.com:9200/_plugin/kopf</code> and viewing the attributes for your node.</p>

<p><img src="../../images/elk/elasticsearch_kopf_hot.png" alt="" /></p>

<p><img src="../../images/elk/elasticsearch_kopf_warm.png" alt="" /></p>

<p>You now have an SSL-enabled ELK stack that will have hot or warm nodes.</p>

<h1>Takeaways</h1>

<p>SSL is enabled by using NGINX as an SSL-listener in front of the ES port <code>9200</code> using self-signed certs. Elasticsearch is configured to use <code>19200</code> but broadcast <code>9200</code>. This lets the nodes themselves talk over SSL using insecure TLS, but they look normal to the outside world. The Load balancer uses ACM from Amazon with a real domain <code>*.dev.mydom.com</code> (in my screenshots) to terminate SSL with a real chain, but communicates over TCP to the ES nodes to the self-signed server.</p>

<p>The reason for doing this: things like to be able to verify the chain, and don&rsquo;t like self-signed certs. As you see in my screen shot, since I used route53 to point <code>es-test.dev.mydom.com</code> to the ELB (which uses a valid ACM cert), everything is encrypted but outward facing services will not have chain errors.</p>

<p>Hot-warm could be better implemented, but for demonstration purposes, 50/50 is fine if you spin up 4+ nodes. If you only use 2 ECS tasks such as the screen shots, you might end up with both hot or both warm. If you&rsquo;re following along, you&rsquo;ll want at least one of each for curator to make sense.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[My Thoughts after six months of Elastic Beanstalk.]]></title>
    <link href="http://marcyoung.us/post/six-months-of-beanstalk"/>
    <updated>2015-11-16T00:00:00-06:00</updated>
    <id>http://marcyoung.us/post/six-months-of-beanstalk</id>
    <content type="html"><![CDATA[<p>We&rsquo;ve been using pure beanstalk at my current gig for six months and here are my thoughts. <!-- more --></p>

<p>I&rsquo;ll start off with the tl;dr: I like beanstalk a lot. When it fits.</p>

<p>I&rsquo;ve written enought deployment mechanisms to go a little crazy in my time. From tagging code in SVN and pushing it to a central store, to purely puppet provisioned instances, to microservices with ad-hoc AMIs to beanstalk. And beanstalk works. If you have a <em>traditional</em> application (by that I mean some consumers, some APIs, and a database of some sort), beanstalk is the (insert here).</p>

<p>Our current stack includes:</p>

<ul>
<li>A backend rails API.</li>
<li>A front-end javascript CMS.</li>
<li>An ad-hoc CRUD API written in rails.</li>
<li>A javascript web-embed written in node.</li>
</ul>


<p>We use jenkins to deploy code changes once tests pass.</p>

<p>And I&rsquo;ve got to say: I&rsquo;m not unhappy. There are very very few tweaks to make any more.</p>

<ul>
<li>All of these have multiple environments (dev/uat/prod), of which dev and uat shut down at night and on weekends.</li>
<li>Deployment includes rollbacks and notifications on failure.</li>
<li>Things auto-scale as expected.</li>
<li>You get all the metrics you really care about out of the box.</li>
</ul>


<p>That said: if it doesn&rsquo;t fit your stack, don&rsquo;t hamstring it. There are many good deployment mechanisms out there, and if your application does not easily fit into the peg that is beanstalk: find something else. We attempted to use it as a deployment mechanism for our cache layer and it failed horribly. Was it because there is no built in support in beanstalk? Yes. But It would be really nice to see beanstalk provide a boiler plate type set up like a template. Basically you just use their default AWS Linux image with no framework on it, provide the deployment scripts, and be able to manage it via beanstalk. That would be fantastic.</p>

<p>The only downside that I have found is that I would really like to re-do our base architecture at AWS to be code-based.
I&rsquo;m pretty much sold on Terraform, but that is my personal choice, and I would really love to see first-hand beanstalk support there. While not a criticism of beanstalk, I&rsquo;ll just be happy and watch <a href="https://github.com/hashicorp/terraform/issues/2799">this issue on terraform about the topic</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fighting a nasty AWS bug for Beanstalk Leader Election]]></title>
    <link href="http://marcyoung.us/post/beanstalk-leader"/>
    <updated>2015-10-20T00:00:00-05:00</updated>
    <id>http://marcyoung.us/post/beanstalk-leader</id>
    <content type="html"><![CDATA[<p>In the last few months I&rsquo;ve been working to move my latest employer to AWS from Heroku and discovered a very nasty bug. <!-- more -->
The move was due to a lot of issues, the least of which being the cost of heroku compared to using what they implement.</p>

<p>None-the-less, everything went smoothly and the API went from roughly 80% uptime to 99.9%.
The cool thing: we used timed auto-scaling to shut down our dev/test instances at night time and on weekends. This saved <em>alot</em> of money. (remember this part).</p>

<p>After about two months, we discovered migrations in our rails application stopped. The code would deploy fine, but migrations just didn&rsquo;t. After much trial and error
it turned out to only happen on dev and test (not production). Parsing the web of beanstalks deployment framework, it turns out they have the concept of a leader. This is good. With the concept of a leader, you ensure that you can deploy to fleets in bulk and things that are stateful will only be run once (on the leader). One of these things is rails migrations, which makes perfect sense.</p>

<p>Somehow, the idea of our leader was lost. Out of all of our instances (2 in dev), neither one was considered a leader. Dropping that to a single instance, you would think: there&rsquo;s your leader right there. Nope.</p>

<p>Through much debugging with AWS support, we discovered that the implementation is based somewhat loosely <a href="https://github.com/blake-education/aws-cfn-bootstrap/blob/master/cfnbootstrap/cfn_client.py">on this</a>.</p>

<p>Turns out that a leader is elected once in the lifecycle of a beanstalk <em>application</em> and is passed around as the instances scale. If all instances are lost simaeltaneously, that leader is gone, and that&rsquo;s the bug. This could be problematic if you&rsquo;re not careful, but beanstalk makes it stupid simple to make sure instances are almost always available. It would take something crazy to lose all at once.</p>

<p>Like shutting down all instances at night.</p>

<p>As of now, the workaround has been to set an environment variable <code>EB_IS_COMMAND_LEADER</code> to <code>true</code>, and set our deployment to 1 at a time. While it works, it ties us back to beanstalks&#8217; internalness and makes our deployment much slower. Not only because it deploys to one at a time, but because each instance is going to run migrations even when not necessary.</p>

<p>Update: they&rsquo;ve fixed it with their latest update as of 11/15/2015. I removed the environment variable and deployed to a fleet, and it behaved as expected</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Purging old beanstalk versions]]></title>
    <link href="http://marcyoung.us/post/beanstalk-purge"/>
    <updated>2015-08-25T00:00:00-05:00</updated>
    <id>http://marcyoung.us/post/beanstalk-purge</id>
    <content type="html"><![CDATA[<p>I recently found out that you can have at most 500 application versions across beanstalk. I wrote a small script to purge it of old ones<!-- more --></p>

<p>I&rsquo;m a big fan of micro-deployments, however that seems to have caused a headache lately (and it turns out you don&rsquo;t want to find this out when you absolutely need to deploy).</p>

<p>My first attempt was to just browse to the S3 folder for our applications and purge them from S3 by the oldest ones, but that could cause a problem if you delete the archive for a currently deployed version. Also, as it turns out, Beanstalk caches this object list, so you still have to go to the EB console and click &lsquo;Refresh&rsquo; in the application versions list.</p>

<p>The better solution was to write a small ruby snippet to run on cron. It will get all application versions, subtract currently deployed ones, sort by date created, and purge all except &lsquo;x&rsquo; many.</p>

<div class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="nb">require</span> <span class="s1">&#39;aws-sdk&#39;</span>

<span class="no">MAX_VERSIONS</span><span class="o">=</span><span class="mi">50</span>
<span class="n">elasticbeanstalk</span> <span class="o">=</span> <span class="no">Aws</span><span class="o">::</span><span class="no">ElasticBeanstalk</span><span class="o">::</span><span class="no">Client</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="ss">region</span><span class="p">:</span> <span class="s1">&#39;us-east-1&#39;</span><span class="p">)</span>

<span class="n">short_versions_to_keep</span> <span class="o">=</span> <span class="n">elasticbeanstalk</span><span class="o">.</span><span class="n">describe_environments</span><span class="o">.</span><span class="n">environments</span><span class="o">.</span><span class="n">each</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span> <span class="o">|</span><span class="n">v</span><span class="o">|</span> <span class="s2">&quot;</span><span class="si">#{</span><span class="n">v</span><span class="o">.</span><span class="n">application_name</span><span class="si">}</span><span class="s2">+</span><span class="si">#{</span><span class="n">v</span><span class="o">.</span><span class="n">version_label</span><span class="si">}</span><span class="s2">&quot;</span> <span class="p">}</span>

<span class="n">version_eligible_for_delete</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">elasticbeanstalk</span><span class="o">.</span><span class="n">describe_application_versions</span><span class="o">.</span><span class="n">application_versions</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">av</span><span class="o">|</span>
  <span class="n">short_version</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">#{</span><span class="n">av</span><span class="o">.</span><span class="n">application_name</span><span class="si">}</span><span class="s2">+</span><span class="si">#{</span><span class="n">av</span><span class="o">.</span><span class="n">version_label</span><span class="si">}</span><span class="s2">&quot;</span>
  <span class="k">next</span> <span class="k">if</span> <span class="n">short_versions_to_keep</span><span class="o">.</span><span class="n">include?</span> <span class="n">short_version</span>
  <span class="n">version_eligible_for_delete</span><span class="o">[</span><span class="n">av</span><span class="o">.</span><span class="n">application_name</span><span class="o">]</span> <span class="o">||=</span> <span class="p">{}</span>
  <span class="n">version_eligible_for_delete</span><span class="o">[</span><span class="n">av</span><span class="o">.</span><span class="n">application_name</span><span class="o">][</span><span class="n">av</span><span class="o">.</span><span class="n">version_label</span><span class="o">]</span> <span class="o">=</span> <span class="n">av</span>
<span class="k">end</span>

<span class="n">version_eligible_for_delete</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="o">|</span>
  <span class="n">version_eligible_for_delete</span><span class="o">[</span><span class="n">key</span><span class="o">]</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">sort</span> <span class="p">{</span> <span class="o">|</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="o">|</span> <span class="n">a</span><span class="o">[</span><span class="mi">1</span><span class="o">].</span><span class="n">date_created</span> <span class="o">&lt;=&gt;</span> <span class="n">b</span><span class="o">[</span><span class="mi">1</span><span class="o">].</span><span class="n">date_created</span> <span class="p">}</span>
  <span class="k">if</span> <span class="n">version_eligible_for_delete</span><span class="o">[</span><span class="n">key</span><span class="o">].</span><span class="n">size</span> <span class="o">&lt;=</span><span class="no">MAX_VERSIONS</span>
    <span class="nb">puts</span> <span class="s2">&quot;</span><span class="si">#{</span><span class="n">key</span><span class="si">}</span><span class="s2"> has only </span><span class="si">#{</span><span class="n">version_eligible_for_delete</span><span class="o">[</span><span class="n">key</span><span class="o">].</span><span class="n">size</span><span class="si">}</span><span class="s2"> versions. Skipping&quot;</span>
    <span class="k">next</span>
  <span class="k">end</span>
  <span class="n">version_eligible_for_delete</span><span class="o">[</span><span class="n">key</span><span class="o">][</span><span class="mi">0</span><span class="o">.</span><span class="n">.version_eligible_for_delete</span><span class="o">[</span><span class="n">key</span><span class="o">].</span><span class="n">size</span><span class="o">-</span><span class="no">MAX_VERSIONS</span><span class="o">].</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">a</span><span class="o">|</span>
    <span class="nb">puts</span> <span class="s2">&quot;Deleting </span><span class="si">#{</span><span class="n">a</span><span class="o">[</span><span class="mi">1</span><span class="o">].</span><span class="n">application_name</span><span class="si">}</span><span class="s2">: </span><span class="si">#{</span><span class="n">a</span><span class="o">[</span><span class="mi">1</span><span class="o">].</span><span class="n">version_label</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">elasticbeanstalk</span><span class="o">.</span><span class="n">delete_application_version</span><span class="p">(</span><span class="ss">application_name</span><span class="p">:</span> <span class="n">a</span><span class="o">[</span><span class="mi">1</span><span class="o">].</span><span class="n">application_name</span><span class="p">,</span> <span class="ss">version_label</span><span class="p">:</span> <span class="n">a</span><span class="o">[</span><span class="mi">1</span><span class="o">].</span><span class="n">version_label</span><span class="p">)</span>
    <span class="nb">sleep</span> <span class="mi">1</span>
  <span class="k">end</span>
<span class="k">end</span></code></pre></div>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Adafruit PiGrrl Pocket Build]]></title>
    <link href="http://marcyoung.us/post/pigrrl-pocket"/>
    <updated>2015-08-20T00:00:00-05:00</updated>
    <id>http://marcyoung.us/post/pigrrl</id>
    <content type="html"><![CDATA[<p>After building the arcade cabinet I saw the PiGrrl Pocket and unfortunately for my pocket: I made one as well. <!-- more --></p>

<p>The Adafruit guide was pretty straight forward and I only blew one raspberry pi in the process (make sure you don&rsquo;t skip the part about disabling the TFT backlight or you&rsquo;ll cross wires during the troubleshooting phase).</p>

<p><img class="left" src="http://marcyoung.us/images/pigrrl1.jpg" title="cabinet 1" >
<img class="left" src="http://marcyoung.us/images/pigrrl2.jpg" title="cabinet 2" >
<img class="left" src="http://marcyoung.us/images/pigrrl3.jpg" title="cabinet 3" >
<img class="left" src="http://marcyoung.us/images/pigrrl4.jpg" title="cabinet 4" >
<img class="left" src="http://marcyoung.us/images/pigrrl5.jpg" title="cabinet 5" >
<img class="left" src="http://marcyoung.us/images/pigrrl6.jpg" title="cabinet 6" >
<img class="left" src="http://marcyoung.us/images/pigrrl7.jpg" title="cabinet 7" >
<img class="left" src="http://marcyoung.us/images/pigrrl8.jpg" title="cabinet 8" >
<img class="left" src="http://marcyoung.us/images/pigrrl9.jpg" title="cabinet 9" >
<img class="left" src="http://marcyoung.us/images/pigrrl10.jpg" title="cabinet 10" >
<img class="left" src="http://marcyoung.us/images/pigrrl11.jpg" title="cabinet 11" ></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[My First (and likely last) MAME cabinet build]]></title>
    <link href="http://marcyoung.us/post/mame-cabinet"/>
    <updated>2015-08-19T00:00:00-05:00</updated>
    <id>http://marcyoung.us/post/cabinet</id>
    <content type="html"><![CDATA[<p>I decided many months ago to build a bar-top cabinet. After many frustrations and failed attempts: it&rsquo;s done.<!-- more --></p>

<p>It was fairly simple after getting the table saw I needed and some parts later on.
Basically it was a fly-by-your seat design with some generic parts.</p>

<ul>
<li>Raspberry Pi running PiPlay</li>
<li>A super cheap <a href="http://www.panelook.com/EJ080NA-04C_Innolux_8.0_LCM_overview_12715.html">8&#8221; LCD with LVDS to HDMI/Composite out</a></li>
<li>Wood.</li>
<li>Arcade buttons and a USB controller for them.</li>
</ul>


<p>After giving up and restarting a few times, lo&#8217; and behold.</p>

<p><img class="left" src="http://marcyoung.us/images/cabinet1.jpg" title="cabinet 1" >
<img class="left" src="http://marcyoung.us/images/cabinet2.jpg" title="cabinet 2" >
<img class="left" src="http://marcyoung.us/images/cabinet3.jpg" title="cabinet 3" >
<img class="left" src="http://marcyoung.us/images/cabinet4.jpg" title="cabinet 4" >
<img class="left" src="http://marcyoung.us/images/cabinet5.jpg" title="cabinet 5" >
<img class="left" src="http://marcyoung.us/images/cabinet6.jpg" title="cabinet 6" >
<img class="left" src="http://marcyoung.us/images/cabinet7.jpg" title="cabinet 7" >
<img class="left" src="http://marcyoung.us/images/cabinet8.jpg" title="cabinet 8" >
<img class="left" src="http://marcyoung.us/images/cabinet9.jpg" title="cabinet 9" >
<img class="left" src="http://marcyoung.us/images/cabinet10.jpg" title="cabinet 10" >
<img class="left" src="http://marcyoung.us/images/cabinet11.jpg" title="cabinet 11" ></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Azure, Github, and a Corporate Proxy]]></title>
    <link href="http://marcyoung.us/post/azure-github-proxy"/>
    <updated>2015-05-18T00:00:00-05:00</updated>
    <id>http://marcyoung.us/post/aspnet-github</id>
    <content type="html"><![CDATA[<p>Recently I started playing around with Azure and deploying an ASP.NET MVC site via its Github linkage. I had some strange issues.<!-- more --></p>

<h1>Problem 1: I am a masochist</h1>

<p>Under the strange suspicion that I had no idea how to actually build NuGet packages and deploy an ASP.NET site via CI/CD I decided to take on the masochistic task upon myself.
If you <a href="https://github.com/myoung34/HelloWorldASP">take a look at my very basic MVC site</a>, you won&rsquo;t see much of interest. None actually, I&rsquo;m not sure why you possibly clicked that link.</p>

<p>It&rsquo;s a basic MVC app using a terrible NuGet package I&rsquo;ve been deploying that adds some string extension methods. If you run that in Visual Studio, all is well.</p>

<h1>Problem 2: The work proxy</h1>

<p>I tried to publish it to Azure using <a href="http://blogs.technet.com/b/cbernier/archive/2013/09/24/deploy-your-web-application-to-windows-azure-from-with-visual-studio.aspx">the publish feature from VS2013 into Azure</a> but immediately ran into a &lsquo;me&rsquo; problem.</p>

<p>You see, I was deploying from my work PC, which is absolutely blocked from doing anything. All of the traffic from my work PC <strong>must</strong> be published through a web proxy on-site.</p>

<p>This is fine for things like Chrome, which pick those settings up automatically. For cygwin (see problem 1) there are a lot of steps to take.</p>

<ul>
<li>wget/Vagrant: I had to export <code>http_proxy</code>, <code>https_proxy</code>, and <code>ftp_proxy</code> (after pulling down the proxy PAC and finding which proxy address to use).</li>
<li>cURL: I had to write a wrapper <code>/usr/local/bin/curl</code>(higher in the PATH) that basically said <code>/usr/bin/curl --proxy 'http://proxyaddress:80' "$@"</code>.</li>
<li>subversion: I had to add <code>http-proxy-host = proxyaddress</code> into <code>~/.subversion/servers</code> in the <code>[global]</code> section.</li>
<li>git: OMG GIT. So here&rsquo;s the thing. git behind a corporate firewall is hard. It can&rsquo;t resolve through DNS and it can&rsquo;t do anything it needs to do.

<ul>
<li>First I installed <a href="http://ntlmaps.sourceforge.net/">ntmlaps</a> into <code>~/software/ntlmaps</code></li>
<li>Next I set my <code>~.bash_profile</code> to start up a command in screen if it hasn&rsquo;t already to start ntlmaps.

<ul>
<li><code>[[ -n $(screen -ls | grep -E 'git-proxy.\*\((A|De)tached\)$') ]] || screen -d -S git-proxy -m python ~/software/ntlmaps/main.py</code></li>
</ul>
</li>
<li>Next I set git to use this proxy: <code>for i in http https; do git config --global $i.proxy http://localhost:5865</code></li>
</ul>
</li>
</ul>


<h1>Problem 3: Visual Studio and Azure Deploy</h1>

<p><a href="http://blog.kloud.com.au/2014/11/13/publish-to-a-new-azure-website-from-behind-a-proxy/">Visual studio cannot deploy to Azure behind a PAC proxy</a>.</p>

<p>Sites like this one claim you can make changes to the VS2013 executable config but I had zero luck.</p>

<p>So little luck in fact that it just plain failed with an unconnectable error.</p>

<p>From then I said nevermind and decided to just link my Azure app to my github repo using the web UI. All went great and it immediately deployed however when I browsed to my website I was <a href="http://www.dotnetthoughts.net/azure-system-methodaccessexception-attempt-by-security-transparent-method/">greeted with this error.</a>.</p>

<p>All of the blog posts and stack overflow questions say to install the WebHelpers NuGet package via <code>Install-Package -Id  Microsoft.AspNet.WebHelpers</code>, but that didn&rsquo;t solve it. It redeployed and had the same error.</p>

<p>The posts also say to just select the <code>Remove additional files at destination</code> checkbox on Visual Studio deploy. Well that&rsquo;s useless because I cannot deploy via visual studio. After fighting long and hard and redeploying via Github repeatedly, I found the answer.</p>

<h1>Answer: Select the <code>Remove additional files at destination</code> no matter what.</h1>

<p>Yup. I changed to the guest network, selected the checkbox, published successfully and all went well. My app was now live.
I then pushed multiple changes/rebases into the github repo, and it&rsquo;s been working fine since.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Well, I wrote a book]]></title>
    <link href="http://marcyoung.us/post/book"/>
    <updated>2015-04-08T00:00:00-05:00</updated>
    <id>http://marcyoung.us/post/book</id>
    <content type="html"><![CDATA[<p>It&rsquo;s been quite a while since my last post, but I promise I have somewhat of a decent reason. I wrote a book on AWS design patterns!<!-- more --></p>

<p>About 4 months ago I was approached about writing a book on UDOO. I turned it down as I didn&rsquo;t feel like I would have enough content to write anything meaningful on it other than I have no idea what the name means. I then stayed on their list and reviewed a book on <a href="https://www.packtpub.com/virtualization-and-cloud/getting-started-red-hat-enterprise-virtualization">RHEV</a> (or the downstream oVirt) as well as a book on <a href="https://www.packtpub.com/networking-and-servers/learning-puppet-security">puppet security</a>.</p>

<p>After doing these reviews I figured &ldquo;why not&rdquo; and asked if there were any topics I could work on. Long story short I wrote <a href="https://www.packtpub.com/web-development/implementing-cloud-design-patterns-aws">a book on implementing design patterns at AWS</a>.</p>

<p>Writing the book was fairly straight-forward and I didn&rsquo;t have too many issues. Basically I borrowed a lot of concepts from the very outdated topics from the Ninja Of Three pages (and by borrowed I mean don&rsquo;t go there) and adapted them for use, updated them to reflect changes at AWS (which get updated so much my book is already out of date before publication - hawt), and gave in depth information on what these patterns mean to DevOps, developers, and customers.</p>

<p>If you&rsquo;re reading this and <strong>really</strong> want to help a newbie out, please purchase it as 100% of the proceeds go to student loans and nice bourbon (order not guaranteed).</p>

<p>The book is pending a last review before publication right now. I submitted a few images for the cover photo that have not been selected by the publisher yet but I give you my top two rejected images.</p>

<p><img src="http://marcyoung.us/images/book.jpg"/><img src="http://marcyoung.us/images/book-alt.jpg"/></p>

<p>Update 4/29/2015: <a href="http://amzn.to/1zrxpZx">It&rsquo;s back up for sale at amazon</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Yet another Puppet module - HBase]]></title>
    <link href="http://marcyoung.us/post/hbase-puppet-module"/>
    <updated>2014-10-28T00:00:00-05:00</updated>
    <id>http://marcyoung.us/post/hbase-puppet-module</id>
    <content type="html"><![CDATA[<p>In my current set-up I have now deployed a very ugly HBase RPM (0.96) with a puppet manifest to help other devs bring up hbase quickly as well as a more resilient version of the same setup to a coworkers hbase stargate project. I decided to sit down and make it &ldquo;legit&rdquo; by adding best-practices and real usage tests. <!-- more --></p>

<p>I present yet another HBase module. Unlike the ones on the forge, however, this one works.</p>

<p>The RPMs are provided by a yum repo from <a href="http://hortonworks.com/hdp/">horton works data platform</a> which are very well made, contain well-catered configuration files, and even uses zookeeper out of the box. If you have made it this far and wish to try it out, it is very simple and works exremely well. While I would NOT use it in production in favor of a clustered set up with Thrift, Region Servers, or even YARN, it will work for most dev set ups. If you use it in production, drop me a line on how well it performs under load.</p>

<p>If you are interested in something more suitable for production I recommand <a href="http://ambari.apache.org/">Ambari</a>. It&rsquo;s extremely awesome. Otherwise, just check out my current module at <a href="https://github.com/myoung34/puppet-hbase">my github</a> or on the <a href="https://forge.puppetlabs.com/myoung34/hbase">puppet forge</a>.</p>

<p>Basic Usage:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>class { 'hbase':
</span><span class='line'>  port =&gt; '8080', #default is '8000'
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[UDOO and an Arduino LCD Part 2 - 3d Printer]]></title>
    <link href="http://marcyoung.us/post/udoo-and-an-arduino-lcd-3d"/>
    <updated>2014-07-26T00:00:00-05:00</updated>
    <id>http://marcyoung.us/post/udoo-3d</id>
    <content type="html"><![CDATA[<p>I finally broke down and bought a <a href="http://www.bukobot.com/bukito">3d printer</a>. <!--more--> It&rsquo;s from Deezmaker, which I got off kickstarter. I took a pre-made udoo case off thingiverse, and modified it to fit my needs. Thankfully, I still remember how to use Blender, which has native STL support.</p>

<p>I expanded it horizontally a little to allow some cord room, and laid the sata drive below it, with a 3d printed spacer. Then mounted the UDOO inside. After much trial and error on the lid, I got snap fit, and some holes cut out for the button and LCD. I added screw mounts, but that didn&rsquo;t work out too well, so I ended up supergluing my home-made PCB&rsquo;s to the underside of it. One is the clock battery, the other is a push button and resistor, attached to an Arduino riser shield just below the screen. Bam.</p>

<p>Also, excuse the not-so-perfect printing and mounting. I&rsquo;ve literally not printed out anything else. Go big or go home folks. Related: I love 3d printing.</p>

<p>For pics, checkout <a href="http://marcyoung.us/post/udoo-and-an-arduino-lcd">the updated page</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[New Puppet Module - MirthConnect]]></title>
    <link href="http://marcyoung.us/post/mirth-puppet-module"/>
    <updated>2014-05-14T00:00:00-05:00</updated>
    <id>http://marcyoung.us/post/mirth-puppet-module</id>
    <content type="html"><![CDATA[<p>I released a new Puppet module to the forge out of another work necessity. Mirth is used pretty heavily for HL7 ETL, and has a ton of other uses. <!-- more --></p>

<p>I started out at my current gig doing this, so it hurt a little to have to automate it, mostly out of fear of getting back into that engine =).</p>

<p>It can be found <a href="https://github.com/myoung34/puppet-mirthconnect">on my github</a> or at the <a href="https://forge.puppetlabs.com/myoung34/mirthconnect">Puppet forge</a>.</p>

<p>Basic Usage:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yumrepo { "my mirth repo":
</span><span class='line'>  baseurl  =&gt; "http://server/pulp/repos/mirthconnect/",
</span><span class='line'>  descr    =&gt; "My Mirth Connect Repository",
</span><span class='line'>  enabled  =&gt; 1,
</span><span class='line'>  gpgcheck =&gt; 0,
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>class { 'mirthconnect':
</span><span class='line'>  provider =&gt; 'yum', #default is 'rpm'
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Complete Continuous Deployment Using Puppet and Pulp - Part 4 - Puppet and Jenkins]]></title>
    <link href="http://marcyoung.us/post/continuous-deployment-using-puppet-and-pulp-pt-4-puppet-jenkins"/>
    <updated>2014-03-22T00:00:00-05:00</updated>
    <id>http://marcyoung.us/post/continuous-deployment-part-4-puppet-and-jenkins</id>
    <content type="html"><![CDATA[<p>So. We have an application that it&rsquo;s constantly pushed to Yum when it&rsquo;s modified. We have a puppet manifest (with tests) that can deploy this application and keep it up to date, and we even have r10k handling the deployment of those puppet modules so that we don&rsquo;t have to worry about dependencies, and we can even stage them! What we don&rsquo;t have is a way of getting changes to that puppet module to the puppet master without remoting in and running r10k. That&rsquo;s easy to fix with jenkins!<!--more--></p>

<p>If you were to stop right now, you&rsquo;re pretty close. But&hellip;remoting into the server to redeploy isn&rsquo;t scalable. What if you forget? What if you have a new guy that made a super awesome bugfix to your puppet module and forgot how to get it up to the servers? Enter jenkins. Note: I have travis-ci set up for the one here, but we&rsquo;re going to duplicate that logic. Travis-CI is nice if your module is on github, but it may not be. Or you may need it to do something else, such as trigger an r10k deployment, so that&rsquo;s why we&rsquo;re still implementing Jenkins.</p>

<h3>The Jenkins job for puppet-exampleservice</h3>

<ol>
<li>Create a free-style job and name it something like <em>puppet-exampleservice</em></li>
<li>Point it to your git repo for the <em>puppet-exampleservice</em> module and have it poll SCM every x minutes.</li>
<li>Have it run in rvm 2.0.0</li>
<li>Create an <strong>execute shell</strong> build step with:</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bundle install
</span><span class='line'>bundle exec rake</span></code></pre></td></tr></table></div></figure>


<ol>
<li>From the <em>warnings</em> plugin, add a <strong>post-build action</strong> to <em>scan for compiler warnings</em>

<ul>
<li>set <em>scan console log</em> to <strong>puppet-lint</strong></li>
</ul>
</li>
</ol>


<p>From here, you now have something similar to Travis-Ci. Hit Build, and it should go green. Congrats, you now have automated testing. What you need now is that automated deployment I&rsquo;ve been hinting at. But that&rsquo;s easy!</p>

<h3>The Jenkins job to re-deploy puppet modules on the ENC</h3>

<ol>
<li>Create a free-style job and name it something like <em>Redeploy Puppet Modules</em></li>
<li>Add a string parameter <strong>git_branch</strong></li>
<li>Add a build step <strong>execute shell script on remote host using ssh</strong>

<ul>
<li>Select your ENC (set one up in the <strong>Manage jenkins</strong> portion first and make sure your private/public keys work) with:</li>
</ul>
</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># Validate the build param. Should be 'dev' or 'master'
</span><span class='line'># This corresponds to the r10k setup.
</span><span class='line'>environment=$(echo "$git_branch" | awk '{split($0,a,"/"); print a[2]}')
</span><span class='line'>if [[ "$environment" == "master" ]]; then
</span><span class='line'>  rm -rf /var/cache/r10k/* # Sometimes r10k won't deploy and acts like it's up to date.
</span><span class='line'>  /usr/bin/r10k deploy environment master -v -p
</span><span class='line'>  exit 0
</span><span class='line'>elif [[ "$environment" == "dev" ]]; then
</span><span class='line'>  rm -rf /var/cache/r10k/* # Sometimes r10k won't deploy and acts like it's up to date.
</span><span class='line'>  /usr/bin/r10k deploy environment dev -v -p
</span><span class='line'>  exit 0
</span><span class='line'>else
</span><span class='line'>  echo "Invalid environment parameter [$environment] passed to build."
</span><span class='line'>  echo "  Should be one of 'dev' or 'master'."
</span><span class='line'>  exit 1
</span><span class='line'>fi</span></code></pre></td></tr></table></div></figure>


<p>You&rsquo;re now ready for your previous module to notify this build.</p>

<ol>
<li>Go back to your puppet module job and:

<ol>
<li>Create a post-build action <strong>trigger parameterized build on other projects</strong></li>
<li>Set &lsquo;projects to build&rsquo; to <strong>Redeploy Puppet Modules</strong></li>
<li>Set &lsquo;Trigger when build is&rsquo; to <strong>Stable or unstable but not failed</strong></li>
<li>Add a parameter &lsquo;Predefined parameters&rsquo; and give it: <code>git_branch=$GIT_BRANCH</code></li>
</ol>
</li>
</ol>


<h3>You&rsquo;re missing a Jenkins job</h3>

<p>Technically you&rsquo;re close, but you might want to redeploy if your r10k changes. You can do that right now!</p>

<ol>
<li>Create a new free-style joba and call it <em>puppet-r10k</em></li>
<li>There are no tests, so just point it at your r10k git repo and watch <em>dev</em> and <em>master</em> branches</li>
<li>Make it poll SCM every x minutes</li>
<li>Create a post-build action <strong>trigger parameterized build on other projects</strong>

<ul>
<li>Set &lsquo;projects to build&rsquo; to <strong>Redeploy Puppet Modules</strong></li>
<li>Set &lsquo;Trigger when build is&rsquo; to <strong>Stable or unstable but not failed</strong></li>
<li>Add a parameter &lsquo;Predefined parameters&rsquo; and give it:</li>
</ul>
</li>
</ol>


<h3>You&rsquo;re Done!!1one</h3>

<p>Now build your puppet module. When it goes green, it will notify the <strong>Redeploy Puppet Modules</strong> job and give it the git branch (<em>dev</em> or <em>master</em>). That build will now parse the git branch, and on the Foreman ENC will run the r10k deployer. Don&rsquo;t you have that fuzzy feeling inside because you can now redeploy your modules to the server by just making a commit? I do and I don&rsquo;t even know you!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Complete Continuous Deployment Using Puppet and Pulp - Part 3 - Enter Puppet]]></title>
    <link href="http://marcyoung.us/post/continuous-deployment-using-puppet-and-pulp-pt-3-enter-puppet"/>
    <updated>2014-03-21T00:00:00-05:00</updated>
    <id>http://marcyoung.us/post/continuous-deployment-part-3-enter-puppet</id>
    <content type="html"><![CDATA[<p>Now that we have a package, we need a way of installing it amirite? We&rsquo;re going to write a puppet module for this package complete with rspec tests<!--more--></p>

<h1>The Module</h1>

<p>The module for this is going to be simple. The application as it is right now is an HTTP server in python. So our module needs to do these things:</p>

<ol>
<li>Manage the package and make sure it&rsquo;s always the latest

<ul>
<li>This ensures that new builds will be reinstalled</li>
</ul>
</li>
<li>Open the firewall for TCP port 8000</li>
<li>Make sure dependencies are installed

<ul>
<li>The RPM has a dependency set for <em>python</em>, so yum would take care of this, but I like to be explicit and not assume that the RPM knows edge cases.</li>
</ul>
</li>
</ol>


<h2>puppet-exampleservice breakdown</h2>

<h3>Files</h3>

<ul>
<li><em>manifests/init.pp</em>

<ul>
<li>This just kickstarts the puppet catalog for this module. It will call our <em>exampleservice.pp</em> class</li>
</ul>
</li>
<li><em>manifests/exampleservice.pp</em>

<ul>
<li>This is the hard worker. It will make sure the service is running, the package is the latest, and that the firewall is open. This implies a dependency on the puppetlabs-firewall module.</li>
</ul>
</li>
<li><em>Puppetfile</em>

<ul>
<li>This will let you know dependencies, such as the <em>puppetlabs-firewall</em> module</li>
</ul>
</li>
<li><em>.travis.yml</em> and <em>.fixtures.yml</em>

<ul>
<li>These are specific to <a href="http://travis-ci.org">travis-ci</a>. If your module will be internal, and not at github, you won&rsquo;t need this. I did so because it&rsquo;s at github. I&rsquo;ll be duplicating this CI at jenkins, and you&rsquo;ll see why later.</li>
</ul>
</li>
<li><em>Rakefile</em>, <em>Gemfile</em>, and <em>spec/</em>

<ul>
<li>These are all part of the testing framework. The tests included for this module are <strong>Puppetlint</strong> (with some disabled checks) and <strong>Rspec-Puppet</strong></li>
</ul>
</li>
</ul>


<h3>Tests</h3>

<ol>
<li>Puppetlint

<ul>
<li>Checks syntax and best practices for your modules. Highly recommended. To make use of this in jenkins, you&rsquo;ll want to take a look at <a href="http://hackers.lookout.com/2012/07/puppet-lint-with-jenkins/">this guide</a></li>
</ul>
</li>
<li>RSpec-Puppet

<ul>
<li>Let&rsquo;s you write assertions for the catalog. Examples would include testing manifest logic, like not doing something if a flag was true or false, etc. See <a href="rspec-puppet.com/tutorial/">the rspec-puppet pages</a></li>
</ul>
</li>
</ol>


<h1>Making your module work via r10k</h1>

<p>You have a module. How do you get it on foreman, or any Puppet master to actually work? Are you going to remote into it, check it out to some repository folder, symlink it to <strong>/etc/puppet/modules</strong> and call it good? That&rsquo;ll work, but how do you manage dependencies? Remember, you need the <em>puppetlabs-firewall</em> module there too for this to work. You&rsquo;ll probably need others. What happens when you have to fix this module? Fix it, see the tests are green (or dear god fix it on the ENC), and call that your process? The point of continous deployment, devops, etc etc is to have <strong>consistency</strong>. Having a one-off process for deploying your configuration management violates what you&rsquo;re trying to solve! Enter <strong>r10k</strong>. Essentially all you need is a new git repository (call this one <a href="https://github.com/myoung34/blog-r10k">blog-r10k</a> that holds information about what modules you need, where they came from, and what versions you want of them and where. This also adds the ability to <strong>stage</strong> modules. You can have a <em>dev</em> branch for your module, deploy it to <em>development</em> nodes, and vice versa. This means you can stop hoping your fix works and prove it before it hits production boxes.</p>

<p>In the <a href="http://marcyoung.us/post/continuous-deployment-using-puppet-and-pulp-pt-1-the-machines/">Part 1</a> I hinted at modifying the <em>[development]</em> and <em>[production]</em> labels in the puppet configuration file. Now is when you find out why.</p>

<h3>Set up r10k</h3>

<p>On your ENC, create a file <strong>/etc/r10k.yaml</strong> with this content:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>:cachedir: '/var/cache/r10k'
</span><span class='line'>:sources:
</span><span class='line'>  :puppet:
</span><span class='line'>    remote: "https://github.com/myoung34/blog-r10k.git"
</span><span class='line'>    basedir: '/etc/puppet/environments'
</span><span class='line'>:purgedirs:
</span><span class='line'>  - /etc/puppet/environments</span></code></pre></td></tr></table></div></figure>


<h3>Deploy your modules the &lsquo;hot&rsquo; way</h3>

<p>How? On the ENC type: <code># r10k deploy environment -v -p</code></p>

<h3>What wizardry is this?!</h3>

<p>That r10k file tells you to purge <em>/etc/puppet/environments</em> and deploy the <em>Puppetfile</em> from the <a href="https://github.com/myoung34/blog-r10k/blob/master/Puppetfile">r10k repo</a> in a similar fashion to Gem, NuGet, etc. You told it to deploy all environments it knew about to that directory. The output showed a <strong>dev</strong> environment and a <strong>master</strong> environment. These are git branches! Each branch in the <a href="https://github.com/myoung34/blog-r10k/blob/master/Puppetfile">r10k repo</a> has a Puppetfile. You&rsquo;ll notice that in the master branch, it said to deploy <em>puppetlabs-firewall</em> and <em>puppet-exampleservice</em>. Look in the dev branch of the <a href="https://github.com/myoung34/blog-r10k/blob/master/Puppetfile">r10k repo</a>. The Puppetfile says to use <code>:ref =&gt; 'dev'</code> for your <em>puppet-exampleservice</em>. You just staged your code. Your <strong>dev</strong> code now deploys to <strong>/etc/puppet/environments/dev/modules</strong> and your <strong>master</strong> code now deploys to <strong>/etc/puppet/environments/master/modules</strong> ! Remember the change you made to your puppet.conf? Any node that has <code>environment = development</code> will generate its catalog using <strong>/etc/puppet/environment/dev/modules</strong> and <code>environment = production</code> will generate its catalog using <strong>/etc/puppet/environment/master/modules</strong>.</p>

<h3>Why you care even if you think you don&rsquo;t</h3>

<p>That passive aggressive statement I had criticizing your workflow above is now null. If you make a change to your module in <strong>dev</strong>, all you have to do is remote into your puppet master where <em>r10k</em> is, and type <code># r10k deploy environment dev -v -p</code>. No more missing dependencies, it&rsquo;s hands off!</p>

<h3>What&rsquo;s missing</h3>

<ol>
<li>Acceptance tests

<ul>
<li>Before this would have been <strong>rspec-system-puppet</strong> but it&rsquo;s deprecated for <a href="https://github.com/puppetlabs/beaker">Beaker</a>. Note that both of these use Vagrant to spin up a siloed Virtual Machine to test the module in isolation. If you&rsquo;re wanting to do this, make sure your jenkins can spin up a virtual machine. If your jenkins is at AWS for example, you&rsquo;d probably want to look at having it spin up an AMI to run this. My current setup does not allow the creation of VMs from a VM (My jenkins is a VM).</li>
</ul>
</li>
</ol>


<h2>What you have at this point in this blog post</h2>

<p>Right now, you have a Jenkins box that generates new RPMs of your application whenever you make changes to it. You also have a manifest that can manage it. However, this is a one-off. If you have to modify your manifest, you have to redeploy it via r10k to the ENC (foreman). It would be nice if you could utilize Jenkins for this. That&rsquo;s in the next post.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Complete Continuous Deployment Using Puppet and Pulp - Part 2 - The Application]]></title>
    <link href="http://marcyoung.us/post/continuous-deployment-using-puppet-and-pulp-pt-2-the-app"/>
    <updated>2014-03-20T00:00:00-05:00</updated>
    <id>http://marcyoung.us/post/continuous-deployment-part-2-the-application</id>
    <content type="html"><![CDATA[<p>Our application will be simple, as its goal is only to demonstrate a daemon that needs to be managed via init.d and packaged as an RPM.<!--more--></p>

<h1>The Application</h1>

<p>Like I said, it&rsquo;s simple. It&rsquo;s going to be a shell script that runs the <em>python SimpleHTTPServer</em> on port 8000, but it brings up some real life issues:</p>

<ul>
<li>How can we package it</li>
<li>How can we ensure the port is open</li>
<li>How can we test it</li>
</ul>


<p>The code is on <a href="https://github.com/myoung34/blog-exampleservice">this github page</a>.</p>

<p>You&rsquo;ll notice the layout mimics its place on the filesystem. This may not be a realistic case, but it sure make sthe POC easy. You&rsquo;ll notice a <strong>Rakefile</strong> in the repository. This is the heart of our packaging for this. If you look into it, you&rsquo;ll see it&rsquo;s essentially a Makefile (see what I did there???). There are many other ways to approach this, but it&rsquo;s the simplest for now. Basically the rake file will parse the <em>version</em> file (which is <a href="http://semver.org/">semantically versioned</a>), and tries to build an RPM via FPM based on it.</p>

<ol>
<li>The <strong>unstable</strong> build will happen as <code>bundle exec rake unstable</code>

<ul>
<li>This will create an rpm such as: <strong>myapp-0.0.1-beta.1.{timestamp}.x86_64.rpm</strong></li>
<li>This is timestamped because many merges to dev can happen before a version bump.</li>
</ul>
</li>
<li>The <strong>stable</strong> build will happen as <code>bundle exec rake stable</code>

<ul>
<li>This will create an rpm such as <strong>myapp-0.0.1-1.x86_64.rpm</strong></li>
<li>There should be no timestamping here, master merges should always be tagged and versioned appropriately.</li>
</ul>
</li>
<li>Both of the previous builds will attempt to upload to the pulp repository we set up.</li>
</ol>


<h1>The Jenkins set up</h1>

<h3>There is a pre-requisite.</h3>

<p>If you look at the Rakefile closely, you&rsquo;ll see (or have wondered already) that pulp-admin requires a username and password. You wouldn&rsquo;t want to put this in the git repository, so the Rakefile has an implicit requirement for a file <strong>.pulp.yml</strong> in the home directory (for Jenkins this should be <em>/usr/lib/jenkins</em>.</p>

<h3>The Jobs</h3>

<ol>
<li>Unstable Job

<ul>
<li>Create a job that watches that git repository&rsquo;s <strong>dev</strong> branch</li>
<li>The git repository is <a href="https://github.com/myoung34/blog-exampleservice.git">https://github.com/myoung34/blog-exampleservice.git</a></li>
<li>Poll SCM every 3 minutes <code>H/3 * * * *</code></li>
<li>Run under rvm. I chose <strong>2.0.0</strong></li>
<li>Run a build script:</li>
</ul>
</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bundle install
</span><span class='line'>bundle exec rake</span></code></pre></td></tr></table></div></figure>


<ol>
<li>Stable Job

<ul>
<li>Create a job that watches that git repository&rsquo;s <strong>master</strong> branch</li>
<li>The git repository is <a href="https://github.com/myoung34/blog-exampleservice.git">https://github.com/myoung34/blog-exampleservice.git</a></li>
<li>Poll SCM every 3 minutes <code>H/3 * * * *</code></li>
<li>Run under rvm. I chose <strong>2.0.0</strong></li>
<li>Run a build script:</li>
</ul>
</li>
</ol>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bundle install
</span><span class='line'>bundle exec rake stable</span></code></pre></td></tr></table></div></figure>


<h1>Profit</h1>

<p>You&rsquo;ll notice that each time you make a change to the git repository, it will build an RPM for it and upload it to the Pulp server. That means that if you&rsquo;re subscribed to that Yum repository, you could do a <code>yum update myapp</code> and you&rsquo;d get a new version. We&rsquo;re getting very close to done =)</p>

<p><img class="left" src="http://marcyoung.us/images/jenkinsbuild.png" title="jenkins" ></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Complete Continuous Deployment Using Puppet and Pulp - Part 1 - The Machines]]></title>
    <link href="http://marcyoung.us/post/continuous-deployment-using-puppet-and-pulp-pt-1-the-machines"/>
    <updated>2014-03-19T00:00:00-05:00</updated>
    <id>http://marcyoung.us/post/continuous-deployment-part-1-the-machines</id>
    <content type="html"><![CDATA[<p>You&rsquo;re going to need a minimum of 4 servers. Before you freak out, that&rsquo;s to keep things simple. Again, calm down. Also, you&rsquo;ll see I like CentOS. All the servers I built were CentOS 6.5 x86_64<!--more--></p>

<h1>Servers</h1>

<h2>Git server</h2>

<p>For this you don&rsquo;t really need to set this one up, but most likely you&rsquo;ll have an internal git server. I&rsquo;ll be using Github for this demo. Use whatever you like.</p>

<h2>Pulp</h2>

<p>Set up the server and client via <a href="http://pulp-user-guide.readthedocs.org/en/pulp-2.3/installation.html">this guide</a>.</p>

<p>When done, go ahead and create an <em>unstable</em> feed via:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>pulp-admin login -uadmin -padmin
</span><span class='line'>pulp-admin rpm repo create --repo-id=unstable \
</span><span class='line'>  --relative-url=unstable --serve-http=true \
</span><span class='line'>  --display-name='Unstable Packages'
</span><span class='line'>pulp-admin logout</span></code></pre></td></tr></table></div></figure>


<h2>Jenkins</h2>

<p>Follow <a href="https://wiki.jenkins-ci.org/display/JENKINS/Installing+Jenkins+on+RedHat+distributions">this guide</a> to set up jenkins.</p>

<p>Install the jenkins plugins:</p>

<ul>
<li>git scm</li>
<li>ssh plugin</li>
<li>rvm</li>
<li>warnings</li>
</ul>


<p>Install these extra Yum packages:</p>

<p><code>yum install -y rpm-build rpm ruby ruby-devel rubygems git automake autoconf gcc gcc-c++</code></p>

<p><a href="http://rvm.io">Set up RVM</a></p>

<p>Install <a href="https://github.com/jordansissel/fpm">FPM</a> via gem: <code>gem install fpm</code></p>

<p>Install the pulp-admin tools the same way you did on the pulp server <strong>Not the server, just the admin tools!</strong></p>

<p>Go ahead an ensure all these bits and pieces work, such as connecting to pulp via the login command, using rvm, etc. Jenkins is the heavy lifter in this stack.</p>

<h2>Foreman</h2>

<p><a href="http://theforeman.org/manuals/1.4/quickstart_guide.html#Installation">The guide for 1.4.1 is here</a></p>

<p>Install <strong>r10k</strong> via gem: <code>gem install r10k</code></p>

<p>Also, install the Puppetlabs yum repository and update puppet to 3.4.2 or higher.</p>

<p>Updating Puppet from 2 to 3 on Foreman requires some configuration changes. To get these, just re-run the <code># foreman-installer</code> command.</p>

<p>Make these changes to <strong>/etc/puppet/puppet.conf</strong> for now:</p>

<ul>
<li>Under the <strong>[master]</strong> section add: <code>hiera_config   = $confdir/hiera/master/hiera.yaml</code></li>
<li>Replace the <strong>[development]</strong> and <strong>[production]</strong> elements at the bottom with:</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[development]
</span><span class='line'>    modulepath     = /etc/puppet/environments/dev/modules:/etc/puppet/modules
</span><span class='line'>    config_version =
</span><span class='line'>[production]
</span><span class='line'>    modulepath     = /etc/puppet/environments/master/modules:/etc/puppet/modules
</span><span class='line'>    config_version =</span></code></pre></td></tr></table></div></figure>


<h2>A puppet node</h2>

<p>Because why not. Install the puppet yum repository and install Puppet 3.4.2 or higher.</p>

<p>Make sure you have <code>pluginsync = true</code> in the <strong>/etc/puppet/puppet.conf</strong> file under <strong>[main]</strong></p>

<p>My assumption before you move on, if you&rsquo;re following along, is that this node can connect to the puppet master (foreman) and generates all green when you run <code># puppet agent -t</code></p>

<p>Lastly, make sure you&rsquo;re subscribed to the Yum repository for the <strong>myapp</strong> package we&rsquo;ve been building so that puppet can install it when we get to that point. To do that, create the file <strong>/etc/yum.repos.d/mypulp.repo</strong> with the contents:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[mypulp]
</span><span class='line'>name=My Pulp Provider - Unstable
</span><span class='line'>baseurl=http://pulp.blindrage.local/pulp/repos/unstable/
</span><span class='line'>enabled=1
</span><span class='line'>gpgcheck=0
</span><span class='line'>metadata_expire=10</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Complete Continuous Deployment Using Puppet and Pulp - Overview]]></title>
    <link href="http://marcyoung.us/post/continuous-deployment-using-puppet-and-pulp-overview"/>
    <updated>2014-03-18T00:00:00-05:00</updated>
    <id>http://marcyoung.us/post/continuous-deployment-overview</id>
    <content type="html"><![CDATA[<p>This will be by far my biggest post to date. I&rsquo;ve been asked from multiple sources about the system I&rsquo;ve set up at my current company, so this is a very small version of it. By the end of this, assuming you follow along, you&rsquo;ll have a multiple node system set up that will deploy a linux service, packaged as an RPM, to internal Yum feeds, with Puppet along the way to keep this continuously deployed. The puppet module I&rsquo;ll write to do this will also be continuous, with all changes to it causing tests to run, and r10k to redeploy them if successful.<!--more--></p>

<p>This series will be in this layout:</p>

<ul>
<li>Overview (this page)</li>
<li><a href="http://marcyoung.us/post/continuous-deployment-using-puppet-and-pulp-pt-1-the-machines/">Part 1 - The Nodes and their purpose in this stack</a></li>
<li><a href="http://marcyoung.us/post/continuous-deployment-using-puppet-and-pulp-pt-2-the-app/">Part 2 - Creating a small linux service that causes new RPM builds when changes are seen via Jenkins</a></li>
<li><a href="http://marcyoung.us/post/continuous-deployment-using-puppet-and-pulp-pt-3-enter-puppet/">Part 3 - Creating a puppet manifest to deploy and maintain the previous package</a></li>
<li><a href="http://marcyoung.us/post/continuous-deployment-using-puppet-and-pulp-pt-4-puppet-jenkins/">Part 4 - Managing the puppet manifests so that changes also run tests and re-deploy to the ENC (foreman)</a>
<!--* [Part 5 - Simplifying your life with vagrant to develop and maintain this setup without worrying about nodes that are subscribed to the packages/puppet manifests]() - not available yet--></li>
</ul>


<h5>Note</h5>

<p>This is by NO MEANS a copy/pasta guide. I&rsquo;m going based on the assumption you just want to see the high level, some code, and the flow. I&rsquo;ll link to guides on how to set up the nodes such as the Pulp server, Foreman server, etc by I won&rsquo;t go into details that don&rsquo;t tie into the end-goal.</p>

<h3>Workflows</h3>

<ol>
<li>Developer workflow

<ul>
<li>Continuous integration of puppet modules

<ul>
<li>Make a change to a puppet module</li>
<li>Jenkins deetects the change and runs tests</li>
<li>Jenkins tells the ENC (puppet master) to re-deploy its modules</li>
</ul>
</li>
<li>Continious Deployment of an application

<ul>
<li>Make a change to your git repository (the package code base)</li>
<li>Jenkins detects the change and runs tests</li>
<li>Jenkins builds an RPM</li>
<li>Jenkins uploads that RPM to a Pulp repository

<ul>
<li>These can be &lsquo;feeds&rsquo;, such as a change to <em>dev</em> branch creating an RPM in an <em>unstable</em> repository. A change to <em>master</em> branch would create an RPM in a <em>stable</em> repository*</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Server workflow (puppet agents)

<ul>
<li>Servers subscribe to a repository (stable or unstable)</li>
<li>A Cron job continuously checks for changes to the package in this Yum feed</li>
<li>A new package is detected and is bootstrapped to the server</li>
</ul>
</li>
</ol>


<h3>Glossary</h3>

<ul>
<li>Pulp - a Yum repository client/server similar to Spacewalk, but much more light weight. Think aptly for Redhat</li>
<li>Jenkins - A continuous integration server written in java</li>
<li>Puppet - A client/server configuration  management suite</li>
<li>Foreman - An ENC for puppet. Allows you to do things such as reports, monitoring etc for Puppet nodes, similar to Puppet Dashboard</li>
<li>Vagrant - A suite that allows you to bootstrap virtual machines, hiding the implementation. Think a CLI that lets you build a base VM, share it, and swap it out for different providers such as vmware, virtualbox, AWS, etc</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[UDOO and an Arduino LCD]]></title>
    <link href="http://marcyoung.us/post/udoo-and-an-arduino-lcd"/>
    <updated>2014-03-03T00:00:00-06:00</updated>
    <id>http://marcyoung.us/post/udoo-lcd</id>
    <content type="html"><![CDATA[<p>I have continued to want more out of my UDOO, so I decided to make use of a cracked LCD I had sitting around from Adafruit, by having the UDOO display system information to it.<!--more-->
A side note: the linux distro I&rsquo;m using is Ubuntu 12.04 LTS for ARM, and by a cracked LCD I mean the digitizer doesn&rsquo;t work. You can modify this code to use the touchscreen functionality of the screen
if you wish.</p>

<p>Here&rsquo;s the parts list:</p>

<ul>
<li><a href="http://www.adafruit.com/products/376">This TFT LCD</a>. It&rsquo;s worth noting they&rsquo;ve made a newer revision, but it shouldn&rsquo;t be any different.</li>
<li><a href="http://www.radioshack.com/product/index.jsp?productId=2062347">A 10k Ohm resistor</a></li>
<li><a href="http://www.radioshack.com/product/index.jsp?productId=18761926">A Jumper kit and board</a> or an <a href="http://www.adafruit.com/products/51">arduino shield</a></li>
<li><a href="http://bit.ly/1eONbBk">A breadboard button</a></li>
</ul>


<p>Here&rsquo;s a short version of the steps:</p>

<ul>
<li>Wire up the button exactly the same as the <a href="http://www.arduino.cc/en/Tutorial/Switch#.UxVG7PldUkA">arduino tutorial</a> to digital 2.</li>
<li><a href="http://learn.adafruit.com/2-8-tft-touch-shield/controlling-the-backlight">Modify your LCD to use Digital 3 to control the backlight</a>.</li>
<li><p>Set up the <code>ttymxc3</code> device in linux for Serial on 9600 baud</p>

<pre><code> sudo stty -F /dev/ttymxc3 cs8 9600 ignbrk -brkint -icrnl -imaxbel \
 -opost -onlcr -isig -icanon -iexten -echo -echoe -echok -echoctl -echoke noflsh -ixon -crtscts
</code></pre>

<ul>
<li>Add that command to <code>/etc/rc.local</code> to make it permanent.</li>
</ul>
</li>
<li><p>Add <a href="https://github.com/myoung34/udoo-lcd-sysinfo/blob/master/script/udoo.sh">this bash script</a> to <code>/usr/local/bin</code></p>

<ul>
<li>Set it for startup by adding <code>sh /usr/local/bin/udoo.sh | cat &gt; /dev/ttymxc3</code> to <code>/etc/rc.local</code></li>
<li><p>Add a cron to update it every minute by adding this to <code>/etc/crontab</code></p>

<pre><code>  * * * * * root sh /usr/local/bin/udoo.sh | cat &gt; /dev/ttymxc3
</code></pre></li>
</ul>
</li>
<li><p>Load <a href="https://github.com/myoung34/udoo-lcd-sysinfo/blob/master/sketch/udoo.ino">this sketch</a> to your Arduino.</p></li>
<li>Reboot the arduino via the <code>RST</code> switch, or by a full power reboot, ensuring you replace the <code>J18</code> jumper so that the chips can communicate.</li>
</ul>


<p>If everything went well, your UDOO should look and act like the pictures below. Good luck!</p>

<p>UPDATED 7/26/2014: Pics attached of the <a href="http://marcyoung.us/post/udoo-and-an-arduino-lcd-3d">3d printed case</a></p>

<p><img class="left" src="http://marcyoung.us/images/IMG_0792.jpg" title="udoo 3" >
<img class="left" src="http://marcyoung.us/images/IMG_0793.jpg" title="udoo 3" >
<img class="left" src="http://marcyoung.us/images/IMG_0794.jpg" title="udoo 3" >
<img class="left" src="http://marcyoung.us/images/IMG_0795.jpg" title="udoo 3" >
<img class="left" src="http://marcyoung.us/images/IMG_0796.jpg" title="udoo 3" >
<img class="left" src="http://marcyoung.us/images/IMG_1003.jpg" title="udoo 3d" >
<img class="left" src="http://marcyoung.us/images/IMG_1004.jpg" title="udoo 3d" >
<img class="left" src="http://marcyoung.us/images/IMG_1005.jpg" title="udoo 3d" >
<img class="left" src="http://marcyoung.us/images/IMG_1006.jpg" title="udoo 3d" >
<img class="left" src="http://marcyoung.us/images/IMG_1007.jpg" title="udoo 3d" >
<img class="left" src="http://marcyoung.us/images/IMG_1008.jpg" title="udoo 3d" >
<img class="left" src="http://marcyoung.us/images/IMG_1010.jpg" title="udoo 3d" >
<img class="left" src="http://marcyoung.us/images/IMG_1012.jpg" title="udoo 3d" ></p>
]]></content>
  </entry>
  
</feed>
