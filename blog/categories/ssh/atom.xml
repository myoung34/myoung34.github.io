<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="https://www.w3.org/2005/Atom">

  <title><![CDATA[Category: ssh | Mark Young]]></title>
  <link href="https://markyoung.us/blog/categories/ssh/atom.xml" rel="self"/>
  <link href="https://markyoung.us/"/>
  <updated>2025-04-28T21:57:27+00:00</updated>
  <id>https://markyoung.us/</id>
  <author>
    <name><![CDATA[Mark Young]]></name>
    
  </author>
  <generator uri="https://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Just In Time SSH Using EC2 Instance Connect]]></title>
    <link href="https://markyoung.us/post/ec2-instance-connect-ssh"/>
    <updated>2023-04-25T00:00:00+00:00</updated>
    <id>https://markyoung.us/post/ec2-instance-connect-ssh</id>
    <content type="html"><![CDATA[<p>I played around with just in time users in EC2 using instance connect and a custom built NSS module <!-- more --></p>

<p>I needed to PoC a solution for SSH users that are backed by an IdP but ran into some issues.</p>

<p>EC2 Instance Connect (IMO) seems to be way under promoted by AWS, and I feel like that&rsquo;s a real disservice if you need (I&rsquo;m so sorry for you) SSH (I do for this case).</p>

<p>The TLDR for ec2 instance connect:</p>

<ul>
<li>A user makes a call <code>aws ec2-instance-connect send-ssh-public-key --instance-id i-08e2c277f1ea9a99a --instance-os-user mark.young --ssh-public-key file:///home/myoung/.ssh/asdf.pub</code></li>
<li>AWS pushes the public key to <code>http://169.254.169.254/latest/meta-data/managed-ssh-keys/active-keys/mark.young</code> for <code>60</code> seconds</li>
<li>The user does <code>ssh -i {private key that matches the public key} mark.young@{public ip of the instance}</code> and gets in.</li>
</ul>


<p>That&rsquo;s crazy cool, but we have a few issues outright (major ones):</p>

<ul>
<li>You can impersonate. There&rsquo;s nothing keeping me from doing <code>--instance-os-user not.me</code> and getting in. Fine in small cases bad for observability. You could tie this back to a user but that sucks. Youd have to tie back the <code>SendSSHPublicKey</code> cloudtrail call with the iam user/role via the request params to the box, and if youre not shipping auth.log youre screwed. If 100 people do this at once you&rsquo;ve lost. There&rsquo;s no way to see which key material let who in to run what. If you thought &ldquo;Oh I&rsquo;ll use sts principaltags&rdquo; I love you. Keep reading.</li>
<li>Users have to exist ahead of time. This is the <strong>big</strong> one. If you thought &ldquo;What if we create them when they send they create the key on the host&rdquo;. You can&rsquo;t. Not easily anyway. If you think it&rsquo;s still solvable or said &ldquo;What about NSS&rdquo; keep reading homie.</li>
<li>There&rsquo;s no documented rate limits. I&rsquo;ve brought this up, no answer yet. I might see if I can break this ;)</li>
<li>You cannot <em>directly</em> do this to private instances. You&rsquo;ll need public instances or bastions to do this. I&rsquo;ll give you a snippet for that too.</li>
</ul>


<p>Let&rsquo;s get started.</p>

<p>First we need to bring up an Okta with IAM identity center.
Sorry peeps but if you think I&rsquo;m doing <strong>that</strong> walkthrough just <code>ctrl+w</code> and touch grass. Not happening.</p>

<p>Let&rsquo;s assume you have a working IdP and you can get into AWS. Let&rsquo;s start there.</p>

<p>So impersonation&hellip;.</p>

<p>The answer here is an SCP and <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_session-tags.html">sts principalTags</a>.
For the principal tags, it&rsquo;s sort of straight forward. Unless you discover an IAM identity center bug like I did.
If you&rsquo;re using IAM identity center: You&rsquo;ll need to use
<code>https://aws.amazon.com/SAML/Attributes/AccessControl:{ attr name}</code>
in Okta.</p>

<p>The bug? Do <strong>not</strong> use both <code>AccessControl</code> and <code>PrincipalTag</code>. Apparently the IdC freaks out during the SAML jank and wont do anything.</p>

<p>So in Okta, add this:</p>

<p><img src="/images/ec2-ssh/okta1.png"></p>

<p>Also while you&rsquo;re add it make sure you&rsquo;re using the nickName for the username.</p>

<p><img src="/images/ec2-ssh/okta2.png"></p>

<p>At this point go ahead and measure success by making sure that your user is in the <code>first.last</code> format and your <code>AssumeRoleWithSAML</code> call in Cloudtrail has the principalTags on the <code>requestParameters</code>. And by that I mean get angry and weep for 8 hours then find out you&rsquo;re hitting an invisible AWS bug. I&rsquo;ll wait.</p>

<p>Thanks for coming back.</p>

<p>Your user doesn&rsquo;t have to be in this format but it tracks with my needs and my SCP as well as my janky NSS code. Modify it if you need. You do you.</p>

<p><img src="/images/ec2-ssh/okta3.png"></p>

<pre><code>    "eventName": "AssumeRoleWithSAML",
    "awsRegion": "us-east-1",
    "sourceIPAddress": "5.3.9.1",
    "userAgent": "aws-internal/3 aws-sdk-java/1.12.451 blahblahblah",
    "requestParameters": {
        "sAMLAssertionID": "_94942c8c-6b73-4912-86f9-14c",
        "roleSessionName": "mark.young",
        "principalTags": {
            "userName": "mark.young"
        },
</code></pre>

<p>OK. Now that you&rsquo;re getting the metadata lets lock it down.</p>

<p>We&rsquo;re going to apply this SCP:</p>

<pre><code>{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "DenyPublicKeyNotOwnedBySelf",
      "Effect": "Deny",
      "Action": "ec2-instance-connect:SendSSHPublicKey",
      "Resource": "*",
      "Condition": {
        "StringNotEquals": {
          "ec2:osuser": "${aws:PrincipalTag/userName}"
        }
      }
    }
  ]
}
</code></pre>

<p>Very cool right?
What we&rsquo;ve done now is said &ldquo;Any call to <code>SendSSHPublicKey</code> has to have a <code>--instance-os-user</code> param that matches your <code>userName</code> principalTag that was set by okta</p>

<p>Prove it:</p>

<pre><code>$ aws ec2-instance-connect send-ssh-public-key \         
    --region us-east-1 \
    --availability-zone us-east-1a \
    --instance-id i-08843505c12cf9d7e \
    --instance-os-user myoung \
    --ssh-public-key file:///home/myoung/.ssh/asdf.pub | jq .

An error occurred (AccessDeniedException) when calling the SendSSHPublicKey operation: User: arn:aws:sts::1111111111:assumed-role/AWSReservedSSO_AdministratorAccess_e3aec0c44fb7c2e0/mark.young is not authorized to perform: ec2-instance-connect:SendSSHPublicKey on resource: arn:aws:ec2:us-east-1:847713735871:instance/i-08843505c12cf9d7e with an explicit deny in a service control policy
</code></pre>



<pre><code>$ aws ec2-instance-connect send-ssh-public-key \
    --region us-east-1 \
    --availability-zone us-east-1a \
    --instance-id i-08843505c12cf9d7e \
    --instance-os-user mark.young \
    --ssh-public-key file:///home/myoung/.ssh/asdf.pub | jq .

{
  "RequestId": "5b47d1c2-f8dc-447b-8a0f-6cd5bf060d89",
  "Success": true
}
</code></pre>

<p>Bam. Now you can&rsquo;t straight up ssh as others outright.</p>

<p>OK that part&rsquo;s done, but we still have another blocker: the user has to exist first.
That sucks if you have a thousand users. I don&rsquo;t know about you but I don&rsquo;t want to have to sit there and crawl Okta for users that may never ssh in.</p>

<p>OK So the way ec2-instance-connect software works (remember above about what SendSSHPublicKey does and ends it to the metadata endpoint):</p>

<ul>
<li>It adds some <code>AuthorizedKeysCommand</code> lines to <code>/etc/ssh/sshd_config</code></li>
<li>When A user tries to SSH in and fails first it will then hit <code>http://169.254.169.254/latest/meta-data/managed-ssh-keys/active-keys/{user name}</code></li>
<li>SSH Requires that user to exist. If it does, and the public key in memory from the metadata endpoint matches their private key: all good come on in bro</li>
</ul>


<p>So we can&rsquo;t rely on crawling, we can&rsquo;t rely on ssh, but we <strong>can</strong> rely on <a href="https://man7.org/linux/man-pages/man5/nss.5.html">nss</a> since thats what ssh relies on for <code>passwd</code>.
OK so I sound like an expert but I&rsquo;m not. A large chunk of this was hacked out by another person at work, but I&rsquo;m familiar enough. Don&rsquo;t lose hope in me yet.</p>

<p>So SSH talks to NSS. We can hook into NSS to do some logic and create a user like <a href="https://github.com/myoung34/ec2-instance-connect-libnss-create">this</a></p>

<p>So now in my user-data I have this sin:</p>

<pre><code>#cloud-config
packages:
 - gcc
 - unzip

write_files:
  - path: /usr/local/bin/install-nss-create.sh
    owner: root:root
    permissions: '0777'
    content: |
      #!/bin/bash
      pushd . &gt;/dev/null 2&gt;&amp;1
      cd /tmp
      curl -sL https://github.com/myoung34/ec2-instance-connect-libnss-create/archive/refs/heads/main.zip -o /tmp/nss-create.zip
      unzip nss-create.zip
      cd ec2-instance-connect-libnss-create-main
      make
      make install
      sed -i.bak 's/^passwd:.*sss files$/passwd:     sss files create files/g' /etc/nsswitch.conf
      popd &gt;/dev/null 2&gt;&amp;1

runcmd:
  - [/usr/local/bin/install-nss-create.sh]
</code></pre>

<p>I basically compile my nss garbage and add <code>create files</code> to <code>passwd</code> in <code>/etc/nsswitch.conf</code></p>

<p>This means that when a user attempts to SSH it will hook in my C code that calls a script
That script does a
<code>curl http://169.254.169.254/latest/meta-data/managed-ssh-keys/active-keys/{user name}</code>.</p>

<p>If it gets a 200-300 code (the user has put a public key in there - remember this only works for 60s) then it will create the user.</p>

<p>After <code>create</code> I still have <code>files</code> so that SSH will go back and look them back up in <code>/etc/passwd</code>. So assuming they ran the <code>aws ec2-instance-connect send-ssh-public-key</code> command then tried to ssh within 60 seconds: they&rsquo;ll have a user with a matching public key and they&rsquo;ll get in.</p>

<p>Bonus: we should be able to do this to get into private instances.</p>

<p>For this proof I&rsquo;m going to assume you have a public instance <code>1.2.3.4</code> and a private instance you want to reach <code>10.0.0.50</code></p>

<p>Let&rsquo;s make your <code>~/.ssh/config</code> file look like this:</p>

<pre><code>Host my-bastion
  IdentityFile ~/.ssh/asdf
  Hostname 1.2.3.4
  User mark.young

Host private-vps
  IdentityFile ~/.ssh/asdf
  ProxyJump my-bastion
  StrictHostKeyChecking no
  Hostname 10.0.0.50
  User mark.young
  UserKnownHostsFile /dev/null
</code></pre>

<p>Let&rsquo;s jump to that <code>private-vps</code> by using the <code>my-bastion</code> as a jump host.
Hint: You&rsquo;ll need to make 2 SendSSHPublicKey calls. One to the public (so you can get into it) and one to the private (so you can also get into it)</p>

<p>First let&rsquo;s prove we can&rsquo;t just get in. So you know I ain&rsquo;t lyin.</p>

<pre><code>$ ssh my-bastion 
mark.young@1.2.3.4: Permission denied (publickey,gssapi-keyex,gssapi-with-mic).

$ ssh private-vps
mark.young@1.2.3.4: Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
kex_exchange_identification: Connection closed by remote host
Connection closed by UNKNOWN port 65535
</code></pre>

<p>Told you. Let&rsquo;s push the key to both. (remember you have 60s. obviously id write a tool for this later).</p>

<pre><code>$ aws ec2-instance-connect send-ssh-public-key \
    --region us-east-1 \
    --availability-zone us-east-1a \
    --instance-id i-08e2c277f1ea9a99a \
    --instance-os-user mark.young \
    --ssh-public-key file:///home/myoung/.ssh/asdf.pub | jq .Success
true

$ aws ec2-instance-connect send-ssh-public-key \
    --region us-east-1 \
    --availability-zone us-east-1a \
    --instance-id i-004b083d55a6d76c7 \
    --instance-os-user mark.young \
    --ssh-public-key file:///home/myoung/.ssh/asdf.pub | jq .Success
true

$ ssh 10.0.0.50
Last login: Tue Apr 25 19:54:31 2023 from ip-10-0-0-50.ec2.internal

   __|  __|  __|
   _|  (   \__ \   Amazon Linux 2 (ECS Optimized)
 ____|\___|____/

For documentation, visit http://aws.amazon.com/documentation/ecs
1 package(s) needed for security, out of 3 available
Run "sudo yum update" to apply all updates.```
</code></pre>

<p>Very cool. So what did we accomplish?</p>

<ul>
<li>New instances have absolutely zero requirements on anything other than that very early PoC libnss module. Ideally I could package that up.</li>
<li>We have the normal SSH auditing story. auth.log lines up. We have cloudtrail logs that tell us people are ssh&#8217;ing in and where.</li>
<li>We have JIT users.</li>
<li>We use the same IAM stories for ssh. If I have 8 accounts I know that you need access to an AWS account to get to the instances into it. We could go further and add more principal tags to say that you can&rsquo;t do sudo unless you have a tag, or that you can&rsquo;t ssh at all if you don&rsquo;t have a certain department. This  is <em>leagues</em> better than some of the paid software I&rsquo;ve tested.</li>
<li>We increased no load to any custom tooling. Teleport has etcd, an SSH CA has some unique problems to solve, etc.</li>
<li>Our onboarding and offboarding story for ssh is now the same as IAM</li>
<li>In an incident etc we can simply block SendSSHPublicKey for suspicious users and <code>pkill</code> sshd for the named user (a win over shared users) on the bastion and effectively kill them off everywhere.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Up and Running With Bless and Enforced MFA - Part 2]]></title>
    <link href="https://markyoung.us/post/bless-part2"/>
    <updated>2017-06-20T00:00:00+00:00</updated>
    <id>https://markyoung.us/post/bless-part2</id>
    <content type="html"><![CDATA[<p>Part 2 of deploying Bless will focus on enforcing MFA and using Lyft’s client. <!-- more --></p>

<p>The problem at this point is that anyone in the ops group can bounce without MFA enforced. We can set up the lyft client, which enforces MFA, but if we dont make other changes, there’s no enforcement of MFA. ie you can still call the netflix client and bounce right in.</p>

<p>The other issue is that Netflix’s bless holds true the idea of a bastion host. In-house, we have IPSec tunnels from our VPC’s to our internal network, so I dont need to bounce through a bastion. So I want anyone to be able to bounce, given that they have permissions (ops) and they used MFA. Lyft’s doesn’t enforce the bastion concept, which is nice.</p>

<h1>Prerequisites</h1>

<p>In the IAM console in AWS, enable an MFA device for your user.</p>

<h2>Setting up the client</h2>

<p>I wrote a wrapper to simplify this. Feel free to not like it, but I put this in my <code>~/.bash_aliases</code> to make it easier:</p>

<pre><code>function bounce() {
  if [[ ! -d ~/.blessclient ]]; then
    pushd . &gt;/dev/null
    git clone https://github.com/lyft/python-blessclient.git ~/.blessclient
    cd $_
    make
    popd &gt;/dev/null
  fi
  INTERNAL_IP=$(ifconfig | grep inet | grep 192 | awk '{ print $2}')
  # This gets weird if you have wired and wifi hooked up (sometimes i do). It might allow the wrong IP and give you a crap error messsage.
  if [[ $(ifconfig | grep inet | grep 192 | awk '{ print $2}' | wc -l) -gt 1 ]] &amp;&amp; [[ -z ${BLESSFIXEDIP} ]]; then
    echo "More than one internal ip found. Disable a network interface or provide it manually via env var 'BLESSFIXEDIP'"
  else
    FILE="$(mktemp)"
    rm -rf ${FILE}*
    ssh-keygen -f ${FILE} -N ""
    BLESS_IDENTITYFILE=${FILE} BLESSFIXEDIP=${BLESSFIXEDIP:-${INTERNAL_IP}} ~/.blessclient/blessclient.run --host $1 --nocache --config ~/.blessclient/blessclient.cfg --region EAST &amp;&amp; ssh -i ${FILE} ec2-user@$1
  fi
}
</code></pre>

<p>Now you can bounce with:</p>

<pre><code>$ bounce 10.0.3.7
Generating public/private rsa key pair.
Your identification has been saved in /var/folders/5j/n9trdvbn3qqdtkshkpvnrkhh0000gp/T/tmp.s2ZdeuJD.
Your public key has been saved in /var/folders/5j/n9trdvbn3qqdtkshkpvnrkhh0000gp/T/tmp.s2ZdeuJD.pub.
The key fingerprint is:
SHA256:CizQBI/ROY8QIeiRjt7rY65jPc/oJDL3MA markyoung@Admins-MacBook-Pro.local
The key's randomart image is:
+---[RSA 2048]----+
|B*+.             |
|++o              |
|=..              |
|.o.*.            |
|. o  S           |
|...+ . .         |
| E .o.           |
|oo= + .          |
|.=*              |
+----[SHA256]-----+
Enter your AWS MFA code: 477821
Requesting certificate for your public key (set BLESSQUIET=1 to suppress these messages)
Finished getting certificate.
Last login: Fri Jun 16 20:14:52 2017 from ip-192-168-1-124.ec2.internal

       __|  __|_  )
       _|  (     /   Amazon Linux AMI
      ___|\___|___|

https://aws.amazon.com/amazon-linux-ami/2017.03-release-notes/
No packages needed for security; 2 packages available
Run "sudo yum update" to apply all updates.
[mark@server ~]$
</code></pre>

<p>Nice! But again, MFA is used, not enforced. Lets change that.</p>

<p>I hinted at my group policy in part 1 for <code>ops</code> that looked like:</p>

<pre><code>resource "aws_iam_group_policy" "bless-client" {
    name = "bless-client_iam_policy"
    group = "${aws_iam_group.ops.id}"
    policy = &lt;&lt;EOF
{
    "Version": "2012-10-17",
    "Statement": [
      {
        "Effect": "Allow",
        "Action": "sts:AssumeRole",
        "Resource": [
          "${data.terraform_remote_state.bless_client_iam.bless-client-role-arn}"
        ]
      },
      {
        "Action": "kms:Encrypt",
        "Effect": "Allow",
        "Resource": [
          "${data.terraform_remote_state.kms.ops_bless_arn}"
        ],
        "Condition": {
          "StringEquals": {
            "kms:EncryptionContext:user_type": "user",
            "kms:EncryptionContext:from": "$${aws:username}"
          }
        }
      }
    ]
}
EOF
}
</code></pre>

<p>But in actuality, it should look more like:</p>

<pre><code>resource "aws_iam_group_policy" "bless-client" {
    name = "assume-bless-role"
    group = "${aws_iam_group.ops.id}"
    policy = &lt;&lt;EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": "sts:AssumeRole",
      "Resource": [
        "${data.terraform_remote_state.bless_client_iam.bless-client-role-arn}"
      ],
      "Condition": {
        "Bool": {
          "aws:MultiFactorAuthPresent": "true"
        }
      }
    },
    {
      "Effect": "Deny",
      "Action": "sts:AssumeRole",
      "Resource": [
        "${data.terraform_remote_state.bless_client_iam.bless-client-role-arn}"
      ],
      "Condition": {"BoolIfExists": {"aws:MultiFactorAuthPresent": false}}
    },
    {
      "Action": "kms:Encrypt",
      "Effect": "Allow",
      "Resource": [
        "${data.terraform_remote_state.kms.ops_bless_arn}"
      ],
      "Condition": {
        "StringEquals": {
          "kms:EncryptionContext:user_type": "user",
          "kms:EncryptionContext:from": "$${aws:username}"
        },
        "Bool": {
          "aws:MultiFactorAuthPresent": "true"
        }
      }
    },
    {
      "Action": "kms:Encrypt",
      "Effect": "Deny",
      "Resource": [
        "${data.terraform_remote_state.kms.ops_bless_arn}"
      ],
      "Condition": {
        "StringEquals": {
          "kms:EncryptionContext:user_type": "user",
          "kms:EncryptionContext:from": "$${aws:username}"
        },
        "BoolIfExists": {
          "aws:MultiFactorAuthPresent": false
        }
      }
    }
  ]
}
EOF
}
</code></pre>

<p>What did we do? We basically said ops users can assume the bless-client role or call kms:Encrypt on that key, but only if they used MFA. If you try the original bless client now, it will fail.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Up and Running With Bless and Enforced MFA - Part 1]]></title>
    <link href="https://markyoung.us/post/bless-part1"/>
    <updated>2017-06-20T00:00:00+00:00</updated>
    <id>https://markyoung.us/post/bless-part1</id>
    <content type="html"><![CDATA[<p>I finally got Netflix’s <a href="https://github.com/netflix/bless">Bless</a> running in production using a forked version of Lyft’s <a href="https://github.com/lyft/python-blessclient">client</a>. This post will focus on the first and easier portion: Bless in Lambda <!-- more --></p>

<h1>Prerequisites</h1>

<p>Time and terraform. I like terraform because I dislike cloudformation. Feel free to adapt.</p>

<h2>Installing Bless</h2>

<p>This is actually the easiest part, because it’s straight forward. Side note: I like bless because of its simplicity. It uses lambda + KMS and nothing more. The permissions are stupid simple. The purpose, after talking to one of the guys behind it, was to make it feel native and un-intrusive. It works.</p>

<h2>Setup Config</h2>

<p>This was the hardest to get going, because configuration always is. The readme says to paste in a function to lambda to generate your password. But thats not needed with the super awesome lambda container from <a href="https://github.com/lambci/docker-lambda">lambci</a>. To do this, create a file function.py with the contents:</p>

<pre><code>import boto3
import base64
import os


def lambda_handler(event, context):
    region = os.environ['AWS_REGION']
    client = boto3.client('kms', region_name=region)
    response = client.encrypt(
    KeyId='kms_key_id',
    Plaintext='totallysecure'
    )

    ciphertext = response['CiphertextBlob']
    return base64.b64encode(ciphertext)
</code></pre>

<p>Now lets run that without using the real lambda. Make sure your access key/id have the required permissions to do <code>kms:Encrypt</code>:</p>

<pre><code>docker run -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID -e AWS_SECRET_ACCESS_KEY=AWS_SECRET_ACCESS_KEY -e AWS_REGION=us-east-1 -v "$PWD":/var/task lambci/lambda:python2.7 function.lambda_handler
START RequestId: 42f85048-91e1-4b48-9376-0563722616f0 Version: $LATEST
END RequestId: 42f85048-91e1-4b48-9376-0563722616f0
REPORT RequestId: 42f85048-91e1-4b48-9376-0563722616f0 Duration: 733 ms Billed Duration: 800 ms Memory Size: 1536 MB Max Memory Used: 25 MB
"some base64 encoded key"
</code></pre>

<h2>The Config</h2>

<p>This is an example of a finished config. Save it as <code>lambda_configs/bless_deploy.cfg</code>:</p>

<pre><code>[Bless Options]
certificate_validity_after_seconds = 120
certificate_validity_before_seconds = 120
entropy_minimum_bits = 2048
random_seed_bytes = 256
logging_level = INFO

[Bless CA]

us-east-1_password = some base64 encoded key from lambci/lambda
ca_private_key_file = foo1.pem

[KMS Auth]
</code></pre>

<h2>Build</h2>

<pre><code>$ virtualenv venv
$ . venv/bin/activate
$ pip install -r requirements.txt
$ make publish 
</code></pre>

<h1>Deploy</h1>

<h2>IAM</h2>

<p>The first piece is the IAM portion for Bless. I need to allow it to:</p>

<ol>
<li>Generate random keys from KMS (obvious)</li>
<li>Decrypt the KMS key that’s the password for Bless. This is generated and</li>
<li>Create the log group (maybe not necesary since Lambda does that for you?)</li>
<li>Push logs</li>
</ol>


<pre><code>resource "aws_iam_role" "bless_lambda" {
    name = "bless_lambda"
    assume_role_policy = &lt;&lt;EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": "lambda.amazonaws.com"
      },
      "Effect": "Allow",
      "Sid": ""
    }
  ]
}
EOF
}

resource "aws_iam_role_policy" "bless_lambda" {
    name = "bless_lambda"
    role = "${aws_iam_role.bless_lambda.id}"
    policy = &lt;&lt;EOF
{
    "Version": "2012-10-17",
    "Statement": [
        {
          "Sid": "Stmt1443036478000",
          "Effect": "Allow",
          "Action": [
              "kms:GenerateRandom",
              "kms:Decrypt"
          ],
          "Resource": [
              "${data.terraform_remote_state.kms.ops_bless_arn}"
          ]
        },
        {
            "Effect": "Allow",
            "Action": "logs:CreateLogGroup",
            "Resource": "arn:aws:logs:us-east-1:*:*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "logs:CreateLogStream",
                "logs:PutLogEvents"
            ],
            "Resource": [
                "arn:aws:logs:us-east-1:*:log-group:/aws/lambda/*"
            ]
        }
    ]
}
EOF
}
</code></pre>

<h2>KMS</h2>

<pre><code>resource "aws_kms_key" "ops-bless" {
    description             = "KMS key for Bless"
    deletion_window_in_days = 7
}

resource "aws_kms_alias" "ops-bless" {
    name          = "alias/ops/bless"
    target_key_id = "${aws_kms_key.ops-bless.key_id}"
}

output "ops_bless_arn" {
  value = "${aws_kms_key.ops-bless.arn}"
}
</code></pre>

<h1>Client</h1>

<h2>Client IAM role to assume</h2>

<p>It basically just allows the invocation of our deployed function:</p>

<pre><code>resource "aws_iam_role" "bless-client" {
    name               = "bless-client"
    path               = "/"
    assume_role_policy = &lt;&lt;EOF
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Action": "lambda:InvokeFunction",
            "Effect": "Allow",
            "Resource": [
                "${data.terraform_remote_state.lambda-bless.bless_arn}"
            ]
        }
    ]
}
EOF
}
</code></pre>

<p>I added this to our <code>ops</code> IAM group so that any ops person can assume the role or use <code>kms:Encrypt</code> from the bless KMS key:</p>

<pre><code>resource "aws_iam_group_policy" "bless-client" {
    name = "bless-client_iam_policy"
    group = "${aws_iam_group.ops.id}"
    policy = &lt;&lt;EOF
{
    "Version": "2012-10-17",
    "Statement": [
      {
        "Effect": "Allow",
        "Action": "sts:AssumeRole",
        "Resource": [
          "${data.terraform_remote_state.bless_client_iam.bless-client-role-arn}"
        ]
      },
      {
        "Action": "kms:Encrypt",
        "Effect": "Allow",
        "Resource": [
          "${data.terraform_remote_state.kms.ops_bless_arn}"
        ],
        "Condition": {
          "StringEquals": {
            "kms:EncryptionContext:user_type": "user",
            "kms:EncryptionContext:from": "$${aws:username}"
          }
        }
      }
    ]
}
EOF
}
</code></pre>

<h2>Client config</h2>

<p>This is an example of what my client config looks like:</p>

<pre><code>[MAIN]
region_aliases: east
kms_service_name: bless
bastion_ips: 192.168.1.6
remote_user: ec2-user

[CLIENT]
domain_regex: (.*\.mycompany\.com|.*\.example\.net|\A10\.[0-9](?:\.[0-9]{1,3}){2}\Z)$
cache_dir: .bless/session
cache_file: bless_cache.json
mfa_cache_dir: .aws/session
mfa_cache_file: token_cache.json
ip_urls: https://api.ipify.org, https://canihazip.com
update_script: update_blessclient.sh

[LAMBDA]
user_role: bless-client
account_id: my account id
functionname: bless
functionversion: $LATEST
certlifetime: 120
ipcachelifetime: 120
timeout_connect: 30
timeout_read: 30

[REGION_EAST]
awsregion: us-east-1
kmsauthkey: my kms id that i used for the original password encrypt
</code></pre>

<h1>Test</h1>

<p>You should now have a lambda that can generate certificates to use. You’ll need to put the public keys from <code>foo1.pub</code> and <code>foo2.pub</code> into your servers at <code>/etc/ssh/cas.pub</code> and add <code>TrustedUserCAKeys /etc/ssh/cas.pub</code> to <code>/etc/ssh/sshd_config</code> You can test this with their client:</p>

<pre><code>function bounce () {
  FILE="$(mktemp)"
  rm -rf ${FILE}
  ssh-keygen -f ${FILE} -N ""
  ./bless_client.py \
    us-east-1 \
    bless \
    testdev $(curl --silent https://ipecho.net/plain) \
    ec2-user $(ifconfig | grep -Eo 'inet (addr:)?([0-9]*\.){3}[0-9]*' | grep -Eo '([0-9]*\.){3}[0-9]*' | grep -v '127.0.0.1') \
    "" \
    ${FILE}.pub ${FILE}-cert.pub
  ssh -i ${FILE} ec2-user@$1 "${@:2}"
}

$ bounce 10.0.0.19
</code></pre>


]]></content>
  </entry>
  
</feed>
